{
  "2602.20144v1": "We present AgentOptics, an agentic AI framework for high-fidelity, autonomous optical system control built on the Model Context Protocol (MCP).",
  "2602.20161v1": "Unified multimodal models can both understand and generate visual content within a single architecture.",
  "2602.20160v1": "We propose tttLRM, a novel large 3D reconstruction model that leverages a Test-Time Training (TTT) layer to enable long-context, autoregressive 3D reconstruction with linear computational...",
  "2602.20159v1": "Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored.",
  "2602.20151v1": "Conformal risk control is an extension of conformal prediction for controlling risk functions beyond miscoverage.",
  "2602.20150v1": "Estimating simulation-ready scenes from real-world observations is crucial for downstream planning and policy learning tasks.",
  "2602.20141v1": "Mean Field Games (MFGs) provide a principled framework for modeling interactions in large population models: at scale, population dynamics become deterministic, with uncertainty entering only...",
  "2602.20135v1": "With the rise of large language models (LLMs), they have become instrumental in applications such as Retrieval-Augmented Generation (RAG).",
  "2602.20117v1": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising approach for training reasoning language models (RLMs) by leveraging supervision from verifiers.",
  "2602.20114v1": "Research in machine unlearning (MU) has gained strong momentum: MU is now widely regarded as a critical capability for building safe and fair AI.",
  "2602.20094v1": "As large language models (LLMs) witness increasing deployment in complex, high-stakes decision-making scenarios, it becomes imperative to ground their reasoning in causality rather than spurious...",
  "2602.20091v1": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by conditioning generation on retrieved external documents, but the effect of retrieved context is often non-trivial.",
  "2602.20084v1": "Data visualization principles, derived from decades of research in design and perception, ensure proper visual communication.",
  "2602.20078v1": "Scaling cooperative multi-agent reinforcement learning (MARL) is fundamentally limited by cross-agent noise: when agents share a common reward, the actions of all $N$ agents jointly determine each...",
  "2602.20064v1": "A conversation with a large language model (LLM) is a sequence of prompts and responses, with each response generated from the preceding conversation.",
  "2602.20059v1": "As multi-agent architectures and agent-to-agent protocols proliferate, a fundamental question arises: what actually happens when autonomous LLM agents interact at scale? We study this question...",
  "2602.20157v1": "Current feed-forward 3D/4D reconstruction systems rely on dense geometry and pose supervision -- expensive to obtain at scale and particularly scarce for dynamic real-world scenes.",
  "2602.20156v1": "LLM agents are evolving rapidly, powered by code execution, tools, and the recently introduced agent skills feature.",
  "2602.20153v1": "We study post-calibration uncertainty for trained ensembles of classifiers.",
  "2602.20152v1": "Inspired by behavioral science, we propose Behavior Learning (BL), a novel general-purpose machine learning framework that learns interpretable and identifiable optimization structures from data,...",
  "2602.20137v1": "Data visualization rules-derived from decades of research in design and perception-ensure trustworthy chart communication.",
  "2602.20134v1": "Epidemiological models increasingly rely on self-reported behavioral data such as vaccination status, mask usage, and social distancing adherence to forecast disease transmission and assess the...",
  "2602.20133v1": "The paradigm of automated program generation is shifting from one-shot generation to inference-time search, where Large Language Models (LLMs) function as semantic mutation operators within...",
  "2602.20132v1": "Current reinforcement learning objectives for large-model reasoning primarily focus on maximizing expected rewards.",
  "2602.20130v1": "Objective: To improve the efficiency of medical question answering (MedQA) with large language models (LLMs) by avoiding unnecessary reasoning while maintaining accuracy.",
  "2602.20126v1": "Diffusion language models (DLMs) have recently emerged as a promising alternative to autoregressive (AR) approaches, enabling parallel token generation beyond a rigid left-to-right order.",
  "2602.20122v1": "How do large language models (LLMs) know what they know? Answering this question has been difficult because pre-training data is often a \"black box\" -- unknown or inaccessible.",
  "2602.20119v1": "Solving long-horizon tasks requires robots to integrate high-level semantic reasoning with low-level physical interaction.",
  "2602.20113v1": "Voice style conversion aims to transform an input utterance to match a target speaker's timbre, accent, and emotion, with a central challenge being the disentanglement of linguistic content from...",
  "2602.20111v1": "We study online learning in the adversarial injection model introduced by [Goel et al.",
  "2602.20104v1": "In human-AI decision making, designing AI that complements human expertise has been a natural strategy to enhance human-AI collaboration, yet it often comes at the cost of decreased AI performance...",
  "2602.20102v1": "Despite the state-of-the-art performance of large language models (LLMs) across diverse tasks, their susceptibility to adversarial attacks and unsafe content generation remains a major obstacle to...",
  "2602.20100v1": "The dependence on expert annotation has long constituted the primary rate-limiting step in the application of artificial intelligence to biomedicine.",
  "2602.20093v1": "Sequential recommendation increasingly employs latent multi-step reasoning to enhance test-time computation.",
  "2602.20092v1": "BabyLM aims to dissolve the boundaries between cognitive modeling and language modeling.",
  "2602.20089v1": "Edge-based representations are fundamental cues for visual understanding, a principle rooted in early vision research and still central today.",
  "2602.20079v1": "We present SemanticNVS, a camera-conditioned multi-view diffusion model for novel view synthesis (NVS), which improves generation quality and consistency by integrating pre-trained semantic...",
  "2602.20076v1": "Solving safety-critical control problem has widely adopted the Control Barrier Function (CBF) method.",
  "2602.20070v1": "We develop a kernel method for generative modeling within the stochastic interpolant framework, replacing neural network training with linear systems.",
  "2602.20069v1": "By selecting a specific input or output of a dioperadic tree, we transform it into a rooted tree and induce a corresponding colored operadic structure.",
  "2602.20068v1": "Deep Neural Networks achieve high performance in vision tasks by learning features from regions of interest (ROI) within images, but their performance degrades when deployed on out-of-distribution...",
  "2602.20066v1": "Accurate heat-demand maps play a crucial role in decarbonizing space heating, yet most municipalities lack detailed building-level data needed to calculate them.",
  "2602.20065v1": "Large Language Models (LLMs) play a critical role in how humans access information.",
  "2602.20062v1": "Pretraining and fine-tuning are central stages in modern machine learning systems.",
  "2602.20060v1": "Generative models have shown great potential in trajectory planning.",
  "2602.20057v1": "Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments.",
  "2602.20055v1": "Visual navigation typically assumes the existence of at least one obstacle-free path between start and goal, which must be discovered/planned by the robot.",
  "2602.20053v1": "Deep learning-based image watermarking, while robust against conventional distortions, remains vulnerable to advanced adversarial and regeneration attacks.",
  "2602.20052v1": "In this study, the output of large language models (LLM) is considered an information source generating an unlimited sequence of symbols drawn from a finite alphabet.",
  "2602.20051v1": "3D human pose estimation (HPE) is characterized by intricate local and global dependencies among joints."
}