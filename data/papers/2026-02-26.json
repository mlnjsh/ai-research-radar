[
  {
    "arxiv_id": "2602.22124v1",
    "title": "SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents",
    "authors": [
      "Patrick Tser Jern Kon",
      "Archana Pradeep",
      "Ang Chen",
      "Alexander P. Ellis",
      "Warren Hunt",
      "Zijian Wang",
      "John Yang",
      "Samuel Thompson"
    ],
    "abstract": "Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We introduce SWE-Protégé, a post-training framework that reframes software repair as an expert-protégé collaboration problem. In SWE-Protégé, an SLM remains the sole decision-maker while learning to selectively seek guidance from a strong expert model, recognize stalled states, and follow through on expert feedback. Our approach combines supervised fine-tuning on expert-augmented trajectories with agentic reinforcement learning that explicitly discourages degenerative looping and unproductive expert collaboration. We lightly post-train Qwen2.5-Coder-7B-Instruct to achieve 42.4% Pass@1 on SWE-bench Verified, a +25.4% improvement over the prior SLM state of the art, while using expert assistance sparsely (~4 calls per task and 11% of total tokens).",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "published": "2026-02-25T17:11:49Z",
    "updated": "2026-02-25T17:11:49Z",
    "url": "https://arxiv.org/abs/2602.22124v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22124v1",
    "relevance_score": 20.0,
    "display_category": "LLMs & Agents",
    "summary": "Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as...",
    "keyword_matches": [
      "RAG",
      "agentic"
    ]
  },
  {
    "arxiv_id": "2602.22208v1",
    "title": "Solaris: Building a Multiplayer Video World Model in Minecraft",
    "authors": [
      "Georgy Savva",
      "Oscar Michel",
      "Daohan Lu",
      "Suppakit Waiwitlikhit",
      "Timothy Meehan",
      "Dhairya Mishra",
      "Srivats Poddar",
      "Jack Lu",
      "Saining Xie"
    ],
    "abstract": "Existing action-conditioned video generation models (video world models) are limited to single-agent perspectives, failing to capture the multi-agent interactions of real-world environments. We introduce Solaris, a multiplayer video world model that simulates consistent multi-view observations. To enable this, we develop a multiplayer data system designed for robust, continuous, and automated data collection on video games such as Minecraft. Unlike prior platforms built for single-player settings, our system supports coordinated multi-agent interaction and synchronized videos + actions capture. Using this system, we collect 12.64 million multiplayer frames and propose an evaluation framework for multiplayer movement, memory, grounding, building, and view consistency. We train Solaris using a staged pipeline that progressively transitions from single-player to multiplayer modeling, combining bidirectional, causal, and Self Forcing training. In the final stage, we introduce Checkpointed Self Forcing, a memory-efficient Self Forcing variant that enables a longer-horizon teacher. Results show our architecture and training design outperform existing baselines. Through open-sourcing our system and models, we hope to lay the groundwork for a new generation of multi-agent world models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T18:59:01Z",
    "updated": "2026-02-25T18:59:01Z",
    "url": "https://arxiv.org/abs/2602.22208v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22208v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Existing action-conditioned video generation models (video world models) are limited to single-agent perspectives, failing to capture the multi-agent interactions of real-world environments.",
    "keyword_matches": [
      "multi-agent"
    ]
  },
  {
    "arxiv_id": "2602.22200v1",
    "title": "SumTablets: A Transliteration Dataset of Sumerian Tablets",
    "authors": [
      "Cole Simmons",
      "Richard Diehl Martinez",
      "Dan Jurafsky"
    ],
    "abstract": "Sumerian transliteration is a conventional system for representing a scholar's interpretation of a tablet in the Latin script. Thanks to visionary digital Assyriology projects such as ETCSL, CDLI, and Oracc, a large number of Sumerian transliterations have been published online, and these data are well-structured for a variety of search and analysis tasks. However, the absence of a comprehensive, accessible dataset pairing transliterations with a digital representation of the tablet's cuneiform glyphs has prevented the application of modern Natural Language Processing (NLP) methods to the task of Sumerian transliteration. To address this gap, we present SumTablets, a dataset pairing Unicode representations of 91,606 Sumerian cuneiform tablets (totaling 6,970,407 glyphs) with the associated transliterations published by Oracc. We construct SumTablets by first preprocessing and standardizing the Oracc transliterations before mapping each reading back to the Unicode representation of the source glyph. Further, we retain parallel structural information (e.g., surfaces, newlines, broken segments) through the use of special tokens. We release SumTablets as a Hugging Face Dataset (CC BY 4.0) and open source data preparation code via GitHub. Additionally, we leverage SumTablets to implement and evaluate two transliteration baselines: (1) weighted sampling from a glyph's possible readings, and (2) fine-tuning an autoregressive language model. Our fine-tuned language model achieves an average transliteration character-level F-score (chrF) of 97.55, demonstrating the immediate potential of transformer-based transliteration models in allowing experts to rapidly verify generated transliterations rather than manually transliterating tablets one-by-one.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-25T18:50:42Z",
    "updated": "2026-02-25T18:50:42Z",
    "url": "https://arxiv.org/abs/2602.22200v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22200v1",
    "relevance_score": 10.0,
    "display_category": "LLMs & Agents",
    "summary": "Sumerian transliteration is a conventional system for representing a scholar's interpretation of a tablet in the Latin script.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22179v1",
    "title": "Learning and Naming Subgroups with Exceptional Survival Characteristics",
    "authors": [
      "Mhd Jawad Al Rahwanji",
      "Sascha Xu",
      "Nils Philipp Walter",
      "Jilles Vreeken"
    ],
    "abstract": "In many applications, it is important to identify subpopulations that survive longer or shorter than the rest of the population. In medicine, for example, it allows determining which patients benefit from treatment, and in predictive maintenance, which components are more likely to fail. Existing methods for discovering subgroups with exceptional survival characteristics require restrictive assumptions about the survival model (e.g. proportional hazards), pre-discretized features, and, as they compare average statistics, tend to overlook individual deviations. In this paper, we propose Sysurv, a fully differentiable, non-parametric method that leverages random survival forests to learn individual survival curves, automatically learns conditions and how to combine these into inherently interpretable rules, so as to select subgroups with exceptional survival characteristics. Empirical evaluation on a wide range of datasets and settings, including a case study on cancer data, shows that Sysurv reveals insightful and actionable survival subgroups.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-25T18:25:47Z",
    "updated": "2026-02-25T18:25:47Z",
    "url": "https://arxiv.org/abs/2602.22179v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22179v1",
    "relevance_score": 10.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "In many applications, it is important to identify subpopulations that survive longer or shorter than the rest of the population.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22175v1",
    "title": "DySCO: Dynamic Attention-Scaling Decoding for Long-Context LMs",
    "authors": [
      "Xi Ye",
      "Wuwei Zhang",
      "Fangcong Yin",
      "Howard Yen",
      "Danqi Chen"
    ],
    "abstract": "Understanding and reasoning over long contexts is a crucial capability for language models (LMs). Although recent models support increasingly long context windows, their accuracy often deteriorates as input length grows. In practice, models often struggle to keep attention aligned with the most relevant context throughout decoding. In this work, we propose DySCO, a novel decoding algorithm for improving long-context reasoning. DySCO leverages retrieval heads--a subset of attention heads specialized for long-context retrieval--to identify task-relevant tokens at each decoding step and explicitly up-weight them. By doing so, DySCO dynamically adjusts attention during generation to better utilize relevant context. The method is training-free and can be applied directly to any off-the-shelf LMs. Across multiple instruction-tuned and reasoning models, DySCO consistently improves performance on challenging long-context reasoning benchmarks, yielding relative gains of up to 25% on MRCR and LongBenchV2 at 128K context length with modest additional compute. Further analysis highlights the importance of both dynamic attention rescaling and retrieval-head-guided selection for the effectiveness of the method, while providing interpretability insights into decoding-time attention behavior. Our code is available at https://github.com/princeton-pli/DySCO.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-25T18:21:35Z",
    "updated": "2026-02-25T18:21:35Z",
    "url": "https://arxiv.org/abs/2602.22175v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22175v1",
    "relevance_score": 10.0,
    "display_category": "LLMs & Agents",
    "summary": "Understanding and reasoning over long contexts is a crucial capability for language models (LMs).",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22145v1",
    "title": "When AI Writes, Whose Voice Remains? Quantifying Cultural Marker Erasure Across World English Varieties in Large Language Models",
    "authors": [
      "Satyam Kumar Navneet",
      "Joydeep Chandra",
      "Yong Zhang"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used to ``professionalize'' workplace communication, often at the cost of linguistic identity. We introduce \"Cultural Ghosting\", the systematic erasure of linguistic markers unique to non-native English varieties during text processing. Through analysis of 22,350 LLM outputs generated from 1,490 culturally marked texts (Indian, Singaporean,& Nigerian English) processed by five models under three prompt conditions, we quantify this phenomenon using two novel metrics: Identity Erasure Rate (IER) & Semantic Preservation Score (SPS). Across all prompts, we find an overall IER of 10.26%, with model-level variation from 3.5% to 20.5% (5.9x range). Crucially, we identify a Semantic Preservation Paradox: models maintain high semantic similarity (mean SPS = 0.748) while systematically erasing cultural markers. Pragmatic markers (politeness conventions) are 1.9x more vulnerable than lexical markers (71.5% vs. 37.1% erasure). Our experiments demonstrate that explicit cultural-preservation prompts reduce erasure by 29% without sacrificing semantic quality.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "published": "2026-02-25T17:54:42Z",
    "updated": "2026-02-25T17:54:42Z",
    "url": "https://arxiv.org/abs/2602.22145v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22145v1",
    "relevance_score": 10.0,
    "display_category": "LLMs & Agents",
    "summary": "Large Language Models (LLMs) are increasingly used to ``professionalize'' workplace communication, often at the cost of linguistic identity.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22143v1",
    "title": "MedTri: A Platform for Structured Medical Report Normalization to Enhance Vision-Language Pretraining",
    "authors": [
      "Yuetan Chu",
      "Xinhua Ma",
      "Xinran Jin",
      "Gongning Luo",
      "Xin Gao"
    ],
    "abstract": "Medical vision-language pretraining increasingly relies on medical reports as large-scale supervisory signals; however, raw reports often exhibit substantial stylistic heterogeneity, variable length, and a considerable amount of image-irrelevant content. Although text normalization is frequently adopted as a preprocessing step in prior work, its design principles and empirical impact on vision-language pretraining remain insufficiently and systematically examined. In this study, we present MedTri, a deployable normalization framework for medical vision-language pretraining that converts free-text reports into a unified [Anatomical Entity: Radiologic Description + Diagnosis Category] triplet. This structured, anatomy-grounded normalization preserves essential morphological and spatial information while removing stylistic noise and image-irrelevant content, providing consistent and image-grounded textual supervision at scale. Across multiple datasets spanning both X-ray and computed tomography (CT) modalities, we demonstrate that structured, anatomy-grounded text normalization is an important factor in medical vision-language pretraining quality, yielding consistent improvements over raw reports and existing normalization baselines. In addition, we illustrate how this normalization can easily support modular text-level augmentation strategies, including knowledge enrichment and anatomy-grounded counterfactual supervision, which provide complementary gains in robustness and generalization without altering the core normalization process. Together, our results position structured text normalization as a critical and generalizable preprocessing component for medical vision-language learning, while MedTri provides this normalization platform. Code and data will be released at https://github.com/Arturia-Pendragon-Iris/MedTri.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T17:49:03Z",
    "updated": "2026-02-25T17:49:03Z",
    "url": "https://arxiv.org/abs/2602.22143v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22143v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Medical vision-language pretraining increasingly relies on medical reports as large-scale supervisory signals; however, raw reports often exhibit substantial stylistic heterogeneity, variable...",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22136v1",
    "title": "SigmaQuant: Hardware-Aware Heterogeneous Quantization Method for Edge DNN Inference",
    "authors": [
      "Qunyou Liu",
      "Pengbo Yu",
      "Marina Zapater",
      "David Atienza"
    ],
    "abstract": "Deep neural networks (DNNs) are essential for performing advanced tasks on edge or mobile devices, yet their deployment is often hindered by severe resource constraints, including limited memory, energy, and computational power. While uniform quantization provides a straightforward approach to compress model and reduce hardware requirement, it fails to fully leverage the varying robustness across layers, and often lead to accuracy degradation or suboptimal resource usage, particularly at low bitwidths. In contrast, heterogeneous quantization, which allocates different bitwidths to individual layers, can mitigate these drawbacks. Nonetheless, current heterogeneous quantization methods either needs huge brute-force design space search or lacks the adaptability to meet different hardware conditions, such as memory size, energy budget, and latency requirement. Filling these gaps, this work introduces \\textbf{\\textit{SigmaQuant}}, an adaptive layer-wise heterogeneous quantization framework designed to efficiently balance accuracy and resource usage for varied edge environments without exhaustive search.",
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-25T17:34:14Z",
    "updated": "2026-02-25T17:34:14Z",
    "url": "https://arxiv.org/abs/2602.22136v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22136v1",
    "relevance_score": 10.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Deep neural networks (DNNs) are essential for performing advanced tasks on edge or mobile devices, yet their deployment is often hindered by severe resource constraints, including limited memory,...",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22120v1",
    "title": "GeoDiv: Framework For Measuring Geographical Diversity In Text-To-Image Models",
    "authors": [
      "Abhipsa Basu",
      "Mohana Singh",
      "Shashank Agnihotri",
      "Margret Keuper",
      "R. Venkatesh Babu"
    ],
    "abstract": "Text-to-image (T2I) models are rapidly gaining popularity, yet their outputs often lack geographical diversity, reinforce stereotypes, and misrepresent regions. Given their broad reach, it is critical to rigorously evaluate how these models portray the world. Existing diversity metrics either rely on curated datasets or focus on surface-level visual similarity, limiting interpretability. We introduce GeoDiv, a framework leveraging large language and vision-language models to assess geographical diversity along two complementary axes: the Socio-Economic Visual Index (SEVI), capturing economic and condition-related cues, and the Visual Diversity Index (VDI), measuring variation in primary entities and backgrounds. Applied to images generated by models such as Stable Diffusion and FLUX.1-dev across $10$ entities and $16$ countries, GeoDiv reveals a consistent lack of diversity and identifies fine-grained attributes where models default to biased portrayals. Strikingly, depictions of countries like India, Nigeria, and Colombia are disproportionately impoverished and worn, reflecting underlying socio-economic biases. These results highlight the need for greater geographical nuance in generative models. GeoDiv provides the first systematic, interpretable framework for measuring such biases, marking a step toward fairer and more inclusive generative systems. Project page: https://abhipsabasu.github.io/geodiv",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T17:08:43Z",
    "updated": "2026-02-25T17:08:43Z",
    "url": "https://arxiv.org/abs/2602.22120v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22120v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Text-to-image (T2I) models are rapidly gaining popularity, yet their outputs often lack geographical diversity, reinforce stereotypes, and misrepresent regions.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22115v1",
    "title": "Slice and Explain: Logic-Based Explanations for Neural Networks through Domain Slicing",
    "authors": [
      "Luiz Fernando Paulino Queiroz",
      "Carlos Henrique Leitão Cavalcante",
      "Thiago Alves Rocha"
    ],
    "abstract": "Neural networks (NNs) are pervasive across various domains but often lack interpretability. To address the growing need for explanations, logic-based approaches have been proposed to explain predictions made by NNs, offering correctness guarantees. However, scalability remains a concern in these methods. This paper proposes an approach leveraging domain slicing to facilitate explanation generation for NNs. By reducing the complexity of logical constraints through slicing, we decrease explanation time by up to 40\\% less time, as indicated through comparative experiments. Our findings highlight the efficacy of domain slicing in enhancing explanation efficiency for NNs.",
    "categories": [
      "cs.LO",
      "cs.LG"
    ],
    "primary_category": "cs.LO",
    "published": "2026-02-25T17:01:52Z",
    "updated": "2026-02-25T17:01:52Z",
    "url": "https://arxiv.org/abs/2602.22115v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22115v1",
    "relevance_score": 10.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Neural networks (NNs) are pervasive across various domains but often lack interpretability.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22098v1",
    "title": "Brain3D: Brain Report Automation via Inflated Vision Transformers in 3D",
    "authors": [
      "Mariano Barone",
      "Francesco Di Serio",
      "Giuseppe Riccio",
      "Antonio Romano",
      "Marco Postiglione",
      "Antonino Ferraro",
      "Vincenzo Moscato"
    ],
    "abstract": "Current medical vision-language models (VLMs) process volumetric brain MRI using 2D slice-based approximations, fragmenting the spatial context required for accurate neuroradiological interpretation. We developed \\textbf{Brain3D}, a staged vision-language framework for automated radiology report generation from 3D brain tumor MRI. Our approach inflates a pretrained 2D medical encoder into a native 3D architecture and progressively aligns it with a causal language model through three stages: contrastive grounding, supervised projector warmup, and LoRA-based linguistic specialization. Unlike generalist 3D medical VLMs, \\textbf{Brain3D} is tailored to neuroradiology, where hemispheric laterality, tumor infiltration patterns, and anatomical localization are critical. Evaluated on 468 subjects (BraTS pathological cases plus healthy controls), our model achieves a Clinical Pathology F1 of 0.951 versus 0.413 for a strong 2D baseline while maintaining perfect specificity on healthy scans. The staged alignment proves essential: contrastive grounding establishes visual-textual correspondence, projector warmup stabilizes conditioning, and LoRA adaptation shifts output from verbose captions to structured clinical reports\\footnote{Our code is publicly available for transparency and reproducibility",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T16:46:45Z",
    "updated": "2026-02-25T16:46:45Z",
    "url": "https://arxiv.org/abs/2602.22098v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22098v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Current medical vision-language models (VLMs) process volumetric brain MRI using 2D slice-based approximations, fragmenting the spatial context required for accurate neuroradiological interpretation.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22096v1",
    "title": "WeatherCity: Urban Scene Reconstruction with Controllable Multi-Weather Transformation",
    "authors": [
      "Wenhua Wu",
      "Huai Guan",
      "Zhe Liu",
      "Hesheng Wang"
    ],
    "abstract": "Editable high-fidelity 4D scenes are crucial for autonomous driving, as they can be applied to end-to-end training and closed-loop simulation. However, existing reconstruction methods are primarily limited to replicating observed scenes and lack the capability for diverse weather simulation. While image-level weather editing methods tend to introduce scene artifacts and offer poor controllability over the weather effects. To address these limitations, we propose WeatherCity, a novel framework for 4D urban scene reconstruction and weather editing. Specifically, we leverage a text-guided image editing model to achieve flexible editing of image weather backgrounds. To tackle the challenge of multi-weather modeling, we introduce a novel weather Gaussian representation based on shared scene features and dedicated weather-specific decoders. This representation is further enhanced with a content consistency optimization, ensuring coherent modeling across different weather conditions. Additionally, we design a physics-driven model that simulates dynamic weather effects through particles and motion patterns. Extensive experiments on multiple datasets and various scenes demonstrate that WeatherCity achieves flexible controllability, high fidelity, and temporal consistency in 4D reconstruction and weather editing. Our framework not only enables fine-grained control over weather conditions (e.g., light rain and heavy snow) but also supports object-level manipulation within the scene.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T16:44:12Z",
    "updated": "2026-02-25T16:44:12Z",
    "url": "https://arxiv.org/abs/2602.22096v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22096v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Editable high-fidelity 4D scenes are crucial for autonomous driving, as they can be applied to end-to-end training and closed-loop simulation.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22094v1",
    "title": "Petri Net Relaxation for Infeasibility Explanation and Sequential Task Planning",
    "authors": [
      "Nguyen Cong Nhat Le",
      "John G. Rogers",
      "Claire N. Bonial",
      "Neil T. Dantam"
    ],
    "abstract": "Plans often change due to changes in the situation or our understanding of the situation. Sometimes, a feasible plan may not even exist, and identifying such infeasibilities is useful to determine when requirements need adjustment. Common planning approaches focus on efficient one-shot planning in feasible cases rather than updating domains or detecting infeasibility. We propose a Petri net reachability relaxation to enable robust invariant synthesis, efficient goal-unreachability detection, and helpful infeasibility explanations. We further leverage incremental constraint solvers to support goal and constraint updates. Empirically, compared to baselines, our system produces a comparable number of invariants, detects up to 2 times more infeasibilities, performs competitively in one-shot planning, and outperforms in sequential plan updates in the tested domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-25T16:39:50Z",
    "updated": "2026-02-25T16:39:50Z",
    "url": "https://arxiv.org/abs/2602.22094v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22094v1",
    "relevance_score": 10.0,
    "display_category": "Retrieval & RAG",
    "summary": "Plans often change due to changes in the situation or our understanding of the situation.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22092v1",
    "title": "Overview of the CXR-LT 2026 Challenge: Multi-Center Long-Tailed and Zero Shot Chest X-ray Classification",
    "authors": [
      "Hexin Dong",
      "Yi Lin",
      "Pengyu Zhou",
      "Fengnian Zhao",
      "Alan Clint Legasto",
      "Mingquan Lin",
      "Hao Chen",
      "Yuzhe Yang",
      "George Shih",
      "Yifan Peng"
    ],
    "abstract": "Chest X-ray (CXR) interpretation is hindered by the long-tailed distribution of pathologies and the open-world nature of clinical environments. Existing benchmarks often rely on closed-set classes from single institutions, failing to capture the prevalence of rare diseases or the appearance of novel findings. To address this, we present the CXR-LT 2026 challenge. This third iteration of the benchmark introduces a multi-center dataset comprising over 145,000 images from PadChest and NIH Chest X-ray datasets. The challenge defines two core tasks: (1) Robust Multi-Label Classification on 30 known classes and (2) Open-World Generalization to 6 unseen (out-of-distribution) rare disease classes. We report the results of the top-performing teams, evaluating them via mean Average Precision (mAP), AUROC, and F1-score. The winning solutions achieved an mAP of 0.5854 on Task 1 and 0.4315 on Task 2, demonstrating that large-scale vision-language pre-training significantly mitigates the performance drop typically associated with zero-shot diagnosis.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T16:39:21Z",
    "updated": "2026-02-25T16:39:21Z",
    "url": "https://arxiv.org/abs/2602.22092v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22092v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Chest X-ray (CXR) interpretation is hindered by the long-tailed distribution of pathologies and the open-world nature of clinical environments.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22091v1",
    "title": "Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos",
    "authors": [
      "Matthew Strong",
      "Wei-Jer Chang",
      "Quentin Herau",
      "Jiezhi Yang",
      "Yihan Hu",
      "Chensheng Peng",
      "Wei Zhan"
    ],
    "abstract": "Ego-centric driving videos available online provide an abundant source of visual data for autonomous driving, yet their lack of annotations makes it difficult to learn representations that capture both semantic structure and 3D geometry. Recent advances in large feedforward spatial models demonstrate that point maps and ego-motion can be inferred in a single forward pass, suggesting a promising direction for scalable driving perception. We therefore propose a label-free, teacher-guided framework for learning autonomous driving representations directly from unposed videos. Unlike prior self-supervised approaches that focus primarily on frame-to-frame consistency, we posit that safe and reactive driving depends critically on temporal context. To this end, we leverage a feedforward architecture equipped with a lightweight autoregressive module, trained using multi-modal supervisory signals that guide the model to jointly predict current and future point maps, camera poses, semantic segmentation, and motion masks. Multi-modal teachers provide sequence-level pseudo-supervision, enabling LFG to learn a unified pseudo-4D representation from raw YouTube videos without poses, labels, or LiDAR. The resulting encoder not only transfers effectively to downstream autonomous driving planning on the NAVSIM benchmark, surpassing multi-camera and LiDAR baselines with only a single monocular camera, but also yields strong performance when evaluated on a range of semantic, geometric, and qualitative motion prediction tasks. These geometry and motion-aware features position LFG as a compelling video-centric foundation model for autonomous driving.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T16:38:53Z",
    "updated": "2026-02-25T16:38:53Z",
    "url": "https://arxiv.org/abs/2602.22091v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22091v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Ego-centric driving videos available online provide an abundant source of visual data for autonomous driving, yet their lack of annotations makes it difficult to learn representations that capture...",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22083v1",
    "title": "Coarsening Bias from Variable Discretization in Causal Functionals",
    "authors": [
      "Xiaxian Ou",
      "Razieh Nabi"
    ],
    "abstract": "A class of causal effect functionals requires integration over conditional densities of continuous variables, as in mediation effects and nonparametric identification in causal graphical models. Estimating such densities and evaluating the resulting integrals can be statistically and computationally demanding. A common workaround is to discretize the variable and replace integrals with finite sums. Although convenient, discretization alters the population-level functional and can induce non-negligible approximation bias, even under correct identification. Under smoothness conditions, we show that this coarsening bias is first order in the bin width and arises at the level of the target functional, distinct from statistical estimation error. We propose a simple bias-reduced functional that evaluates the outcome regression at within-bin conditional means, eliminating the leading term and yielding a second-order approximation error. We derive plug-in and one-step estimators for the bias-reduced functional. Simulations demonstrate substantial bias reduction and near-nominal confidence interval coverage, even under coarse binning. Our results provide a simple framework for controlling the impact of variable discretization on parameter approximation and estimation.",
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "stat.ME",
    "published": "2026-02-25T16:32:04Z",
    "updated": "2026-02-25T16:32:04Z",
    "url": "https://arxiv.org/abs/2602.22083v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22083v1",
    "relevance_score": 10.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "A class of causal effect functionals requires integration over conditional densities of continuous variables, as in mediation effects and nonparametric identification in causal graphical models.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22067v1",
    "title": "Semantic Partial Grounding via LLMs",
    "authors": [
      "Giuseppe Canonaco",
      "Alberto Pozanco",
      "Daniel Borrajo"
    ],
    "abstract": "Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding only the most promising operators, guided by predictive models. However, these approaches primarily rely on relational features or learned embeddings and do not leverage the textual and structural cues present in PDDL descriptions. We propose SPG-LLM, which uses LLMs to analyze the domain and problem files to heuristically identify potentially irrelevant objects, actions, and predicates prior to grounding, significantly reducing the size of the grounded task. Across seven hard-to-ground benchmarks, SPG-LLM achieves faster grounding-often by orders of magnitude-while delivering comparable or better plan costs in some domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-25T16:13:26Z",
    "updated": "2026-02-25T16:13:26Z",
    "url": "https://arxiv.org/abs/2602.22067v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22067v1",
    "relevance_score": 10.0,
    "display_category": "Retrieval & RAG",
    "summary": "Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22052v1",
    "title": "AutoSew: A Geometric Approach to Stitching Prediction with Graph Neural Networks",
    "authors": [
      "Pablo Ríos-Navarro",
      "Elena Garces",
      "Jorge Lopez-Moreno"
    ],
    "abstract": "Automating garment assembly from sewing patterns remains a significant challenge due to the lack of standardized annotation protocols and the frequent absence of semantic cues. Existing methods often rely on panel labels or handcrafted heuristics, which limit their applicability to real-world, non-conforming patterns. We present AutoSew, a fully automatic, geometry-based approach for predicting stitch correspondences directly from 2D pattern contours. AutoSew formulates the problem as a graph matching task, leveraging a Graph Neural Network to capture local and global geometric context, and employing a differentiable optimal transport solver to infer stitching relationships-including multi-edge connections. To support this task, we update the GarmentCodeData dataset modifying over 18k patterns with realistic multi-edge annotations, reflecting industrial assembly scenarios. AutoSew achieves 96% F1-score and successfully assembles 73.3% of test garments without error, outperforming existing methods while relying solely on geometric input. Our results demonstrate that geometry alone can robustly guide stitching prediction, enabling scalable garment assembly without manual input.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T16:03:33Z",
    "updated": "2026-02-25T16:03:33Z",
    "url": "https://arxiv.org/abs/2602.22052v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22052v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Automating garment assembly from sewing patterns remains a significant challenge due to the lack of standardized annotation protocols and the frequent absence of semantic cues.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.22212v1",
    "title": "Neu-PiG: Neural Preconditioned Grids for Fast Dynamic Surface Reconstruction on Long Sequences",
    "authors": [
      "Julian Kaltheuner",
      "Hannah Dröge",
      "Markus Plack",
      "Patrick Stotko",
      "Reinhard Klein"
    ],
    "abstract": "Temporally consistent surface reconstruction of dynamic 3D objects from unstructured point cloud data remains challenging, especially for very long sequences. Existing methods either optimize deformations incrementally, risking drift and requiring long runtimes, or rely on complex learned models that demand category-specific training. We present Neu-PiG, a fast deformation optimization method based on a novel preconditioned latent-grid encoding that distributes spatial features parameterized on the position and normal direction of a keyframe surface. Our method encodes entire deformations across all time steps at various spatial scales into a multi-resolution latent grid, parameterized by the position and normal direction of a reference surface from a single keyframe. This latent representation is then augmented for time modulation and decoded into per-frame 6-DoF deformations via a lightweight multilayer perceptron (MLP). To achieve high-fidelity, drift-free surface reconstructions in seconds, we employ Sobolev preconditioning during gradient-based training of the latent space, completely avoiding the need for any explicit correspondences or further priors. Experiments across diverse human and animal datasets demonstrate that Neu-PiG outperforms state-the-art approaches, offering both superior accuracy and scalability to long sequences while running at least 60x faster than existing training-free methods and achieving inference speeds on the same order as heavy pretrained models.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T18:59:53Z",
    "updated": "2026-02-25T18:59:53Z",
    "url": "https://arxiv.org/abs/2602.22212v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22212v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Temporally consistent surface reconstruction of dynamic 3D objects from unstructured point cloud data remains challenging, especially for very long sequences.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22209v1",
    "title": "WHOLE: World-Grounded Hand-Object Lifted from Egocentric Videos",
    "authors": [
      "Yufei Ye",
      "Jiaman Li",
      "Ryan Rong",
      "C. Karen Liu"
    ],
    "abstract": "Egocentric manipulation videos are highly challenging due to severe occlusions during interactions and frequent object entries and exits from the camera view as the person moves. Current methods typically focus on recovering either hand or object pose in isolation, but both struggle during interactions and fail to handle out-of-sight cases. Moreover, their independent predictions often lead to inconsistent hand-object relations. We introduce WHOLE, a method that holistically reconstructs hand and object motion in world space from egocentric videos given object templates. Our key insight is to learn a generative prior over hand-object motion to jointly reason about their interactions. At test time, the pretrained prior is guided to generate trajectories that conform to the video observations. This joint generative reconstruction substantially outperforms approaches that process hands and objects separately followed by post-processing. WHOLE achieves state-of-the-art performance on hand motion estimation, 6D object pose estimation, and their relative interaction reconstruction. Project website: https://judyye.github.io/whole-www",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T18:59:10Z",
    "updated": "2026-02-25T18:59:10Z",
    "url": "https://arxiv.org/abs/2602.22209v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22209v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Egocentric manipulation videos are highly challenging due to severe occlusions during interactions and frequent object entries and exits from the camera view as the person moves.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22207v1",
    "title": "Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets",
    "authors": [
      "Hanna Yukhymenko",
      "Anton Alexandrov",
      "Martin Vechev"
    ],
    "abstract": "The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this work, we present a fully automated framework designed to address these challenges by enabling scalable, high-quality translation of datasets and benchmarks. We demonstrate that adapting test-time compute scaling strategies, specifically Universal Self-Improvement (USI) and our proposed multi-round ranking method, T-RANK, allows for significantly higher quality outputs compared to traditional pipelines. Our framework ensures that benchmarks preserve their original task structure and linguistic nuances during localization. We apply this approach to translate popular benchmarks and datasets into eight Eastern and Southern European languages (Ukrainian, Bulgarian, Slovak, Romanian, Lithuanian, Estonian, Turkish, Greek). Evaluations using both reference-based metrics and LLM-as-a-judge show that our translations surpass existing resources, resulting in more accurate downstream model assessment. We release both the framework and the improved benchmarks to facilitate robust and reproducible multilingual AI development.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-25T18:58:25Z",
    "updated": "2026-02-25T18:58:25Z",
    "url": "https://arxiv.org/abs/2602.22207v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22207v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22197v1",
    "title": "Off-The-Shelf Image-to-Image Models Are All You Need To Defeat Image Protection Schemes",
    "authors": [
      "Xavier Pleimling",
      "Sifat Muhammad Abdullah",
      "Gunjan Balde",
      "Peng Gao",
      "Mainack Mondal",
      "Murtuza Jadliwala",
      "Bimal Viswanath"
    ],
    "abstract": "Advances in Generative AI (GenAI) have led to the development of various protection strategies to prevent the unauthorized use of images. These methods rely on adding imperceptible protective perturbations to images to thwart misuse such as style mimicry or deepfake manipulations. Although previous attacks on these protections required specialized, purpose-built methods, we demonstrate that this is no longer necessary. We show that off-the-shelf image-to-image GenAI models can be repurposed as generic ``denoisers\" using a simple text prompt, effectively removing a wide range of protective perturbations. Across 8 case studies spanning 6 diverse protection schemes, our general-purpose attack not only circumvents these defenses but also outperforms existing specialized attacks while preserving the image's utility for the adversary. Our findings reveal a critical and widespread vulnerability in the current landscape of image protection, indicating that many schemes provide a false sense of security. We stress the urgent need to develop robust defenses and establish that any future protection mechanism must be benchmarked against attacks from off-the-shelf GenAI models. Code is available in this repository: https://github.com/mlsecviswanath/img2imgdenoiser",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T18:46:30Z",
    "updated": "2026-02-25T18:46:30Z",
    "url": "https://arxiv.org/abs/2602.22197v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22197v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Advances in Generative AI (GenAI) have led to the development of various protection strategies to prevent the unauthorized use of images.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22193v1",
    "title": "Improving Parametric Knowledge Access in Reasoning Language Models",
    "authors": [
      "Melody Ma",
      "John Hewitt"
    ],
    "abstract": "We study reasoning for accessing world knowledge stored in a language model's parameters. For example, recalling that Canberra is Australia's capital may benefit from thinking through major cities and the concept of purpose-built capitals. While reasoning language models are trained via reinforcement learning to produce reasoning traces on tasks such as mathematics, they may not reason well for accessing their own world knowledge. We first find that models do not generate their best world knowledge reasoning by default: adding a simple \"think step-by-step\" cue demonstrates statistically significant improvement in knowledge recall but not math. Motivated by this, we propose training models to reason over their parametric knowledge using world-knowledge question answering as a verifiable reward. After reinforcement learning on TriviaQA (+9.9%), performance also improves on Natural Questions, HotpotQA, SimpleQA, and StrategyQA by 4.2%, 2.1%, 0.6%, and 3.0%, respectively. Reasoning models are under-optimized for parametric knowledge access, but can be easily trained to reason better.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-25T18:43:01Z",
    "updated": "2026-02-25T18:43:01Z",
    "url": "https://arxiv.org/abs/2602.22193v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22193v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "We study reasoning for accessing world knowledge stored in a language model's parameters.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22190v1",
    "title": "GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL",
    "authors": [
      "Rui Yang",
      "Qianhui Wu",
      "Zhaoyang Wang",
      "Hanyang Chen",
      "Ke Yang",
      "Hao Cheng",
      "Huaxiu Yao",
      "Baoling Peng",
      "Huan Zhang",
      "Jianfeng Gao",
      "Tong Zhang"
    ],
    "abstract": "Open-source native GUI agents still lag behind closed-source systems on long-horizon navigation tasks. This gap stems from two limitations: a shortage of high-quality, action-aligned reasoning data, and the direct adoption of generic post-training pipelines that overlook the unique challenges of GUI agents. We identify two fundamental issues in these pipelines: (i) standard SFT with CoT reasoning often hurts grounding, and (ii) step-wise RLVR-tyle training faces partial verifiability, where multiple actions can be correct but only a single demonstrated action is used for verification. This makes offline step-wise metrics weak predictors of online task success. In this work, we present GUI-Libra, a tailored training recipe that addresses these challenges. First, to mitigate the scarcity of action-aligned reasoning data, we introduce a data construction and filtering pipeline and release a curated 81K GUI reasoning dataset. Second, to reconcile reasoning with grounding, we propose action-aware SFT that mixes reasoning-then-action and direct-action data and reweights tokens to emphasize action and grounding. Third, to stabilize RL under partial verifiability, we identify the overlooked importance of KL regularization in RLVR and show that a KL trust region is critical for improving offline-to-online predictability; we further introduce success-adaptive scaling to downweight unreliable negative gradients. Across diverse web and mobile benchmarks, GUI-Libra consistently improves both step-wise accuracy and end-to-end task completion. Our results suggest that carefully designed post-training and data curation can unlock significantly stronger task-solving capabilities without costly online data collection. We release our dataset, code, and models to facilitate further research on data-efficient post-training for reasoning-capable GUI agents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-25T18:34:57Z",
    "updated": "2026-02-25T18:34:57Z",
    "url": "https://arxiv.org/abs/2602.22190v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22190v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Open-source native GUI agents still lag behind closed-source systems on long-horizon navigation tasks.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22188v1",
    "title": "Surrogate models for Rock-Fluid Interaction: A Grid-Size-Invariant Approach",
    "authors": [
      "Nathalie C. Pinheiro",
      "Donghu Guo",
      "Hannah P. Menke",
      "Aniket C. Joshi",
      "Claire E. Heaney",
      "Ahmed H. ElSheikh",
      "Christopher C. Pain"
    ],
    "abstract": "Modelling rock-fluid interaction requires solving a set of partial differential equations (PDEs) to predict the flow behaviour and the reactions of the fluid with the rock on the interfaces. Conventional high-fidelity numerical models require a high resolution to obtain reliable results, resulting in huge computational expense. This restricts the applicability of these models for multi-query problems, such as uncertainty quantification and optimisation, which require running numerous scenarios. As a cheaper alternative to high-fidelity models, this work develops eight surrogate models for predicting the fluid flow in porous media. Four of these are reduced-order models (ROM) based on one neural network for compression and another for prediction. The other four are single neural networks with the property of grid-size invariance; a term which we use to refer to image-to-image models that are capable of inferring on computational domains that are larger than those used during training. In addition to the novel grid-size-invariant framework for surrogate models, we compare the predictive performance of UNet and UNet++ architectures, and demonstrate that UNet++ outperforms UNet for surrogate models. Furthermore, we show that the grid-size-invariant approach is a reliable way to reduce memory consumption during training, resulting in good correlation between predicted and ground-truth values and outperforming the ROMs analysed. The application analysed is particularly challenging because fluid-induced rock dissolution results in a non-static solid field and, consequently, it cannot be used to help in adjustments of the future prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-25T18:34:03Z",
    "updated": "2026-02-25T18:34:03Z",
    "url": "https://arxiv.org/abs/2602.22188v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22188v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Modelling rock-fluid interaction requires solving a set of partial differential equations (PDEs) to predict the flow behaviour and the reactions of the fluid with the rock on the interfaces.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22182v1",
    "title": "LiCQA : A Lightweight Complex Question Answering System",
    "authors": [
      "Sourav Saha",
      "Dwaipayan Roy",
      "Mandar Mitra"
    ],
    "abstract": "Over the last twenty years, significant progress has been made in designing and implementing Question Answering (QA) systems. However, addressing complex questions, the answers to which are spread across multiple documents, remains a challenging problem. Recent QA systems that are designed to handle complex questions work either on the basis of knowledge graphs, or utilise contem- porary neural models that are expensive to train, in terms of both computational resources and the volume of training data required. In this paper, we present LiCQA, an unsupervised question answer- ing model that works primarily on the basis of corpus evidence. We empirically compare the effectiveness and efficiency of LiCQA with two recently presented QA systems, which are based on different underlying principles. The results of our experiments show that LiCQA significantly outperforms these two state-of-the-art systems on benchmark data with noteworthy reduction in latency.",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-25T18:28:38Z",
    "updated": "2026-02-25T18:28:38Z",
    "url": "https://arxiv.org/abs/2602.22182v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22182v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Over the last twenty years, significant progress has been made in designing and implementing Question Answering (QA) systems.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22176v1",
    "title": "Mixed Magnification Aggregation for Generalizable Region-Level Representations in Computational Pathology",
    "authors": [
      "Eric Zimmermann",
      "Julian Viret",
      "Michal Zelechowski",
      "James Brian Hall",
      "Neil Tenenholtz",
      "Adam Casson",
      "George Shaikovski",
      "Eugene Vorontsov",
      "Siqi Liu",
      "Kristen A Severson"
    ],
    "abstract": "In recent years, a standard computational pathology workflow has emerged where whole slide images are cropped into tiles, these tiles are processed using a foundation model, and task-specific models are built using the resulting representations. At least 15 different foundation models have been proposed, and the vast majority are trained exclusively with tiles using the 20$\\times$ magnification. However, it is well known that certain histologic features can only be discerned with larger context windows and requires a pathologist to zoom in and out when analyzing a whole slide image. Furthermore, creating 224$\\times$224 pixel crops at 20$\\times$ leads to a large number of tiles per slide, which can be gigapixel in size. To more accurately capture multi-resolution features and investigate the possibility of reducing the number of representations per slide, we propose a region-level mixing encoder. Our approach jointly fuses image tile representations of a mixed magnification foundation model using a masked embedding modeling pretraining step. We explore a design space for pretraining the proposed mixed-magnification region aggregators and evaluate our models on transfer to biomarker prediction tasks representing various cancer types. Results demonstrate cancer dependent improvements in predictive performance, highlighting the importance of spatial context and understanding.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T18:23:42Z",
    "updated": "2026-02-25T18:23:42Z",
    "url": "https://arxiv.org/abs/2602.22176v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22176v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "In recent years, a standard computational pathology workflow has emerged where whole slide images are cropped into tiles, these tiles are processed using a foundation model, and task-specific...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22159v1",
    "title": "CASR: A Robust Cyclic Framework for Arbitrary Large-Scale Super-Resolution with Distribution Alignment and Self-Similarity Awareness",
    "authors": [
      "Wenhao Guo",
      "Zhaoran Zhao",
      "Peng Lu",
      "Sheng Li",
      "Qian Qiao",
      "RuiDe Li"
    ],
    "abstract": "Arbitrary-Scale SR (ASISR) remains fundamentally limited by cross-scale distribution shift: once the inference scale leaves the training range, noise, blur, and artifacts accumulate sharply. We revisit this challenge from a cross-scale distribution transition perspective and propose CASR, a simple yet highly efficient cyclic SR framework that reformulates ultra-magnification as a sequence of in-distribution scale transitions. This design ensures stable inference at arbitrary scales while requiring only a single model. CASR tackles two major bottlenecks: distribution drift across iterations and patch-wise diffusion inconsistencies. The proposed SDAM module aligns structural distributions via superpixel aggregation, preventing error accumulation, while SARM module restores high-frequency textures by enforcing autocorrelation and embedding LR self-similarity priors. Despite using only a single model, our approach significantly reduces distribution drift, preserves long-range texture consistency, and achieves superior generalization even at extreme magnification.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T18:05:51Z",
    "updated": "2026-02-25T18:05:51Z",
    "url": "https://arxiv.org/abs/2602.22159v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22159v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Arbitrary-Scale SR (ASISR) remains fundamentally limited by cross-scale distribution shift: once the inference scale leaves the training range, noise, blur, and artifacts accumulate sharply.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22157v1",
    "title": "Dynamic Personality Adaptation in Large Language Models via State Machines",
    "authors": [
      "Leon Pielage",
      "Ole Hätscher",
      "Mitja Back",
      "Bernhard Marschall",
      "Benjamin Risse"
    ],
    "abstract": "The inability of Large Language Models (LLMs) to modulate their personality expression in response to evolving dialogue dynamics hinders their performance in complex, interactive contexts. We propose a model-agnostic framework for dynamic personality simulation that employs state machines to represent latent personality states, where transition probabilities are dynamically adapted to the conversational context. Part of our architecture is a modular pipeline for continuous personality scoring that evaluates dialogues along latent axes while remaining agnostic to the specific personality models, their dimensions, transition mechanisms, or LLMs used. These scores function as dynamic state variables that systematically reconfigure the system prompt, steering behavioral alignment throughout the interaction.We evaluate this framework by operationalizing the Interpersonal Circumplex (IPC) in a medical education setting. Results demonstrate that the system successfully adapts its personality state to user inputs, but also influences user behavior, thereby facilitating de-escalation training. Notably, the scoring pipeline maintains comparable precision even when utilizing lightweight, fine-tuned classifiers instead of large-scale LLMs. This work demonstrates the feasibility of modular, personality-adaptive architectures for education, customer support, and broader human-computer interaction.",
    "categories": [
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-25T18:05:11Z",
    "updated": "2026-02-25T18:05:11Z",
    "url": "https://arxiv.org/abs/2602.22157v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22157v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "The inability of Large Language Models (LLMs) to modulate their personality expression in response to evolving dialogue dynamics hinders their performance in complex, interactive contexts.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22150v1",
    "title": "CoLoGen: Progressive Learning of Concept`-`Localization Duality for Unified Image Generation",
    "authors": [
      "YuXin Song",
      "Yu Lu",
      "Haoyuan Sun",
      "Huanjin Yao",
      "Fanglong Liu",
      "Yifan Sun",
      "Haocheng Feng",
      "Hang Zhou",
      "Jingdong Wang"
    ],
    "abstract": "Unified conditional image generation remains difficult because different tasks depend on fundamentally different internal representations. Some require conceptual understanding for semantic synthesis, while others rely on localization cues for spatial precision. Forcing these heterogeneous tasks to share a single representation leads to concept`-`localization representational conflict. To address this issue, we propose CoLoGen, a unified diffusion framework that progressively learns and reconciles this concept`-`localization duality. CoLoGen uses a staged curriculum that first builds core conceptual and localization abilities, then adapts them to diverse visual conditions, and finally refines their synergy for complex instruction`-`driven tasks. Central to this process is the Progressive Representation Weaving (PRW) module, which dynamically routes features to specialized experts and stably integrates their outputs across stages. Experiments on editing, controllable generation, and customized generation show that CoLoGen achieves competitive or superior performance, offering a principled representational perspective for unified image generation.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T17:59:29Z",
    "updated": "2026-02-25T17:59:29Z",
    "url": "https://arxiv.org/abs/2602.22150v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22150v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Unified conditional image generation remains difficult because different tasks depend on fundamentally different internal representations.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22149v1",
    "title": "Enhancing Framingham Cardiovascular Risk Score Transparency through Logic-Based XAI",
    "authors": [
      "Emannuel L. de A. Bezerra",
      "Luiz H. T. Viana",
      "Vinícius P. Chagas",
      "Diogo E. Rolim",
      "Thiago Alves Rocha",
      "Carlos H. L. Cavalcante"
    ],
    "abstract": "Cardiovascular disease (CVD) remains one of the leading global health challenges, accounting for more than 19 million deaths worldwide. To address this, several tools that aim to predict CVD risk and support clinical decision making have been developed. In particular, the Framingham Risk Score (FRS) is one of the most widely used and recommended worldwide. However, it does not explain why a patient was assigned to a particular risk category nor how it can be reduced. Due to this lack of transparency, we present a logical explainer for the FRS. Based on first-order logic and explainable artificial intelligence (XAI) fundaments, the explainer is capable of identifying a minimal set of patient attributes that are sufficient to explain a given risk classification. Our explainer also produces actionable scenarios that illustrate which modifiable variables would reduce a patient's risk category. We evaluated all possible input combinations of the FRS (over 22,000 samples) and tested them with our explainer, successfully identifying important risk factors and suggesting focused interventions for each case. The results may improve clinician trust and facilitate a wider implementation of CVD risk assessment by converting opaque scores into transparent and prescriptive insights, particularly in areas with restricted access to specialists.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "published": "2026-02-25T17:58:11Z",
    "updated": "2026-02-25T17:58:11Z",
    "url": "https://arxiv.org/abs/2602.22149v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22149v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Cardiovascular disease (CVD) remains one of the leading global health challenges, accounting for more than 19 million deaths worldwide.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22146v1",
    "title": "Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual",
    "authors": [
      "Yining Li",
      "Peizhong Ju",
      "Ness Shroff"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) plays a significant role in aligning Large Language Models (LLMs) with human preferences. While RLHF with expected reward constraints can be formulated as a primal-dual optimization problem, standard primal-dual methods only guarantee convergence with a distributional policy where the saddle-point problem is in convex-concave form. Moreover, standard primal-dual methods may exhibit instability or divergence in the last iterate under policy parameterization in practical applications. In this work, we propose a universal primal-dual framework for safe RLHF that unifies a broad class of existing alignment algorithms, including safe-RLHF, one-shot, and multi-shot based methods. Building on this framework, we introduce an optimistic primal-dual (OPD) algorithm that incorporates predictive updates for both primal and dual variables to stabilize saddle-point dynamics. We establish last-iterate convergence guarantees for the proposed method, covering both exact policy optimization in the distributional space and convergence to a neighborhood of the optimal solution whose gap is related to approximation error and bias under parameterized policies. Our analysis reveals that optimism plays a crucial role in mitigating oscillations inherent to constrained alignment objectives, thereby closing a key theoretical gap between constrained RL and practical RLHF.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-25T17:54:52Z",
    "updated": "2026-02-25T17:54:52Z",
    "url": "https://arxiv.org/abs/2602.22146v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22146v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Reinforcement Learning from Human Feedback (RLHF) plays a significant role in aligning Large Language Models (LLMs) with human preferences.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22144v1",
    "title": "NoLan: Mitigating Object Hallucinations in Large Vision-Language Models via Dynamic Suppression of Language Priors",
    "authors": [
      "Lingfeng Ren",
      "Weihao Yu",
      "Runpeng Yu",
      "Xinchao Wang"
    ],
    "abstract": "Object hallucination is a critical issue in Large Vision-Language Models (LVLMs), where outputs include objects that do not appear in the input image. A natural question arises from this phenomenon: Which component of the LVLM pipeline primarily contributes to object hallucinations? The vision encoder to perceive visual information, or the language decoder to generate text responses? In this work, we strive to answer this question through designing a systematic experiment to analyze the roles of the vision encoder and the language decoder in hallucination generation. Our observations reveal that object hallucinations are predominantly associated with the strong priors from the language decoder. Based on this finding, we propose a simple and training-free framework, No-Language-Hallucination Decoding, NoLan, which refines the output distribution by dynamically suppressing language priors, modulated based on the output distribution difference between multimodal and text-only inputs. Experimental results demonstrate that NoLan effectively reduces object hallucinations across various LVLMs on different tasks. For instance, NoLan achieves substantial improvements on POPE, enhancing the accuracy of LLaVA-1.5 7B and Qwen-VL 7B by up to 6.45 and 7.21, respectively. The code is publicly available at: https://github.com/lingfengren/NoLan.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T17:50:41Z",
    "updated": "2026-02-25T17:50:41Z",
    "url": "https://arxiv.org/abs/2602.22144v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22144v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Object hallucination is a critical issue in Large Vision-Language Models (LVLMs), where outputs include objects that do not appear in the input image.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22142v1",
    "title": "WeaveTime: Stream from Earlier Frames into Emergent Memory in VideoLLMs",
    "authors": [
      "Yulin Zhang",
      "Cheng Shi",
      "Sibei Yang"
    ],
    "abstract": "Recent advances in Multimodal Large Language Models have greatly improved visual understanding and reasoning, yet their quadratic attention and offline training protocols make them ill-suited for streaming settings where frames arrive sequentially and future observations are inaccessible. We diagnose a core limitation of current Video-LLMs, namely Time-Agnosticism, in which videos are treated as an unordered bag of evidence rather than a causally ordered sequence, yielding two failures in streams: temporal order ambiguity, in which the model cannot follow or reason over the correct chronological order, and past-current focus blindness where it fails to distinguish present observations from accumulated history. We present WeaveTime, a simple, efficient, and model agnostic framework that first teaches order and then uses order. We introduce a lightweight Temporal Reconstruction objective-our Streaming Order Perception enhancement-that instills order aware representations with minimal finetuning and no specialized streaming data. At inference, a Past-Current Dynamic Focus Cache performs uncertainty triggered, coarse-to-fine retrieval, expanding history only when needed. Plugged into exsiting Video-LLM without architectural changes, WeaveTime delivers consistent gains on representative streaming benchmarks, improving accuracy while reducing latency. These results establish WeaveTime as a practical path toward time aware stream Video-LLMs under strict online, time causal constraints. Code and weights will be made publicly available. Project Page: https://zhangyl4.github.io/publications/weavetime/",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T17:45:45Z",
    "updated": "2026-02-25T17:45:45Z",
    "url": "https://arxiv.org/abs/2602.22142v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22142v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Recent advances in Multimodal Large Language Models have greatly improved visual understanding and reasoning, yet their quadratic attention and offline training protocols make them ill-suited for...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22140v1",
    "title": "Lumosaic: Hyperspectral Video via Active Illumination and Coded-Exposure Pixels",
    "authors": [
      "Dhruv Verma",
      "Andrew Qiu",
      "Roberto Rangel",
      "Ayandev Barman",
      "Hao Yang",
      "Chenjia Hu",
      "Fengqi Zhang",
      "Roman Genov",
      "David B. Lindell",
      "Kiriakos N. Kutulakos",
      "Alex Mariakakis"
    ],
    "abstract": "We present Lumosaic, a compact active hyperspectral video system designed for real-time capture of dynamic scenes. Our approach combines a narrowband LED array with a coded-exposure-pixel (CEP) camera capable of high-speed, per-pixel exposure control, enabling joint encoding of scene information across space, time, and wavelength within each video frame. Unlike passive snapshot systems that divide light across multiple spectral channels simultaneously and assume no motion during a frame's exposure, Lumosaic actively synchronizes illumination and pixel-wise exposure, improving photon utilization and preserving spectral fidelity under motion. A learning-based reconstruction pipeline then recovers 31-channel hyperspectral (400-700 nm) video at 30 fps and VGA resolution, producing temporally coherent and spectrally accurate reconstructions. Experiments on synthetic and real data demonstrate that Lumosaic significantly improves reconstruction fidelity and temporal stability over existing snapshot hyperspectral imaging systems, enabling robust hyperspectral video across diverse materials and motion conditions.",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "published": "2026-02-25T17:42:44Z",
    "updated": "2026-02-25T17:42:44Z",
    "url": "https://arxiv.org/abs/2602.22140v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22140v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "We present Lumosaic, a compact active hyperspectral video system designed for real-time capture of dynamic scenes.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22130v1",
    "title": "Sample Complexity Bounds for Robust Mean Estimation with Mean-Shift Contamination",
    "authors": [
      "Ilias Diakonikolas",
      "Giannis Iakovidis",
      "Daniel M. Kane",
      "Sihan Liu"
    ],
    "abstract": "We study the basic task of mean estimation in the presence of mean-shift contamination. In the mean-shift contamination model, an adversary is allowed to replace a small constant fraction of the clean samples by samples drawn from arbitrarily shifted versions of the base distribution. Prior work characterized the sample complexity of this task for the special cases of the Gaussian and Laplace distributions. Specifically, it was shown that consistent estimation is possible in these cases, a property that is provably impossible in Huber's contamination model. An open question posed in earlier work was to determine the sample complexity of mean estimation in the mean-shift contamination model for general base distributions. In this work, we study and essentially resolve this open question. Specifically, we show that, under mild spectral conditions on the characteristic function of the (potentially multivariate) base distribution, there exists a sample-efficient algorithm that estimates the target mean to any desired accuracy. We complement our upper bound with a qualitatively matching sample complexity lower bound. Our techniques make critical use of Fourier analysis, and in particular introduce the notion of a Fourier witness as an essential ingredient of our upper and lower bounds.",
    "categories": [
      "cs.LG",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-25T17:21:23Z",
    "updated": "2026-02-25T17:21:23Z",
    "url": "https://arxiv.org/abs/2602.22130v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22130v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "We study the basic task of mean estimation in the presence of mean-shift contamination.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22125v1",
    "title": "IndicIFEval: A Benchmark for Verifiable Instruction-Following Evaluation in 14 Indic Languages",
    "authors": [
      "Thanmay Jayakumar",
      "Mohammed Safi Ur Rahman Khan",
      "Raj Dabre",
      "Ratish Puduppully",
      "Anoop Kunchukuttan"
    ],
    "abstract": "Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers. We introduce IndicIFEval, a benchmark evaluating constrained generation of LLMs across 14 Indic languages using automatically verifiable, rule-based instructions. It comprises around 800 human-verified examples per language spread across two complementary subsets: IndicIFEval-Ground, translated prompts from IFEval (Zhou et al., 2023) carefully localized for Indic contexts, and IndicIFEval-Ground, synthetically generated instructions grounded in native Indic content. We conduct a comprehensive evaluation of major open-weight and proprietary models spanning both reasoning and non-reasoning models. While models maintain strong adherence to formatting constraints, they struggle significantly with lexical and cross-lingual tasks -- and despite progress in high-resource languages, instruction-following across the broader Indic family lags significantly behind English. We release IndicIFEval and its evaluation scripts to support progress on multilingual constrained generation (http://github.com/ai4bharat/IndicIFEval).",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-25T17:12:37Z",
    "updated": "2026-02-25T17:12:37Z",
    "url": "https://arxiv.org/abs/2602.22125v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22125v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22122v1",
    "title": "Probing the Geometry of Diffusion Models with the String Method",
    "authors": [
      "Elio Moreau",
      "Florentin Coeurdoux",
      "Grégoire Ferre",
      "Eric Vanden-Eijnden"
    ],
    "abstract": "Understanding the geometry of learned distributions is fundamental to improving and interpreting diffusion models, yet systematic tools for exploring their landscape remain limited. Standard latent-space interpolations fail to respect the structure of the learned distribution, often traversing low-density regions. We introduce a framework based on the string method that computes continuous paths between samples by evolving curves under the learned score function. Operating on pretrained models without retraining, our approach interpolates between three regimes: pure generative transport, which yields continuous sample paths; gradient-dominated dynamics, which recover minimum energy paths (MEPs); and finite-temperature string dynamics, which compute principal curves -- self-consistent paths that balance energy and entropy. We demonstrate that the choice of regime matters in practice. For image diffusion models, MEPs contain high-likelihood but unrealistic ''cartoon'' images, confirming prior observations that likelihood maxima appear unrealistic; principal curves instead yield realistic morphing sequences despite lower likelihood. For protein structure prediction, our method computes transition pathways between metastable conformers directly from models trained on static structures, yielding paths with physically plausible intermediates. Together, these results establish the string method as a principled tool for probing the modal structure of diffusion models -- identifying modes, characterizing barriers, and mapping connectivity in complex learned distributions.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "published": "2026-02-25T17:10:59Z",
    "updated": "2026-02-25T17:10:59Z",
    "url": "https://arxiv.org/abs/2602.22122v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22122v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Understanding the geometry of learned distributions is fundamental to improving and interpreting diffusion models, yet systematic tools for exploring their landscape remain limited.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22107v1",
    "title": "Don't stop me now: Rethinking Validation Criteria for Model Parameter Selection",
    "authors": [
      "Andrea Apicella",
      "Francesco Isgrò",
      "Andrea Pollastro",
      "Roberto Prevete"
    ],
    "abstract": "Despite the extensive literature on training loss functions, the evaluation of generalization on the validation set remains underexplored. In this work, we conduct a systematic empirical and statistical study of how the validation criterion used for model selection affects test performance in neural classifiers, with attention to early stopping. Using fully connected networks on standard benchmarks under $k$-fold evaluation, we compare: (i) early stopping with patience and (ii) post-hoc selection over all epochs (i.e. no early stopping). Models are trained with cross-entropy, C-Loss, or PolyLoss; the model parameter selection on the validation set is made using accuracy or one of the three loss functions, each considered independently. Three main findings emerge. (1) Early stopping based on validation accuracy performs worst, consistently selecting checkpoints with lower test accuracy than both loss-based early stopping and post-hoc selection. (2) Loss-based validation criteria yield comparable and more stable test accuracy. (3) Across datasets and folds, any single validation rule often underperforms the test-optimal checkpoint. Overall, the selected model typically achieves test-set performance statistically lower than the best performance across all epochs, regardless of the validation criterion. Our results suggest avoiding validation accuracy (in particular with early stopping) for parameter selection, favoring loss-based validation criteria.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-25T16:56:14Z",
    "updated": "2026-02-25T16:56:14Z",
    "url": "https://arxiv.org/abs/2602.22107v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22107v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Despite the extensive literature on training loss functions, the evaluation of generalization on the validation set remains underexplored.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22101v1",
    "title": "On Imbalanced Regression with Hoeffding Trees",
    "authors": [
      "Pantia-Marina Alchirch",
      "Dimitrios I. Diochnos"
    ],
    "abstract": "Many real-world applications provide a continuous stream of data that is subsequently used by machine learning models to solve regression tasks of interest. Hoeffding trees and their variants have a long-standing tradition due to their effectiveness, either alone or as base models in broader ensembles. At the same time a recent line of work in batch learning has shown that kernel density estimation (KDE) is an effective approach for smoothed predictions in imbalanced regression tasks [Yang et al., 2021]. Moreover, another recent line of work for batch learning, called hierarchical shrinkage (HS) [Agarwal et al., 2022], has introduced a post-hoc regularization method for decision trees that does not alter the structure of the learned tree. Using a telescoping argument we cast KDE to streaming environments and extend the implementation of HS to incremental decision tree models. Armed with these extensions we investigate the performance of decision trees that may enjoy such options in datasets commonly used for regression in online settings. We conclude that KDE is beneficial in the early parts of the stream, while HS hardly, if ever, offers performance benefits. Our code is publicly available at: https://github.com/marinaAlchirch/DSFA_2026.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-25T16:48:07Z",
    "updated": "2026-02-25T16:48:07Z",
    "url": "https://arxiv.org/abs/2602.22101v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22101v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Many real-world applications provide a continuous stream of data that is subsequently used by machine learning models to solve regression tasks of interest.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22090v1",
    "title": "Confidence-Driven Multi-Scale Model Selection for Cost-Efficient Inference",
    "authors": [
      "Bo-Wei Chen",
      "Chung-Chi Chen",
      "An-Zi Yen"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized inference across diverse natural language tasks, with larger models performing better but at higher computational costs. We propose a confidence-driven strategy that dynamically selects the most suitable model based on confidence estimates. By assessing a model's confidence in handling the task and response accuracy, tasks that are likely to be solved correctly are retained, while more uncertain or complex cases are delegated to a larger model, ensuring reliability while minimizing computation. Specifically, we evaluate a model's likelihood of knowing the correct answer and the probability that its response is accurate. Experiments on the Massive Multitask Language Understanding (MMLU) benchmark show that our approach achieves accuracy comparable to the largest model while reducing computational costs by 20\\% to 40\\%. When applied to GPT-4o API calls, it reduces token usage by approximately 60\\%, further improving cost efficiency. These findings indicate the potential of confidence-based model selection to enhance real-world LLM deployment, particularly in resource-constrained settings such as edge devices and commercial API applications.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-25T16:38:03Z",
    "updated": "2026-02-25T16:38:03Z",
    "url": "https://arxiv.org/abs/2602.22090v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22090v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Large Language Models (LLMs) have revolutionized inference across diverse natural language tasks, with larger models performing better but at higher computational costs.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22086v1",
    "title": "MBD-ML: Many-body dispersion from machine learning for molecules and materials",
    "authors": [
      "Evgeny Moerman",
      "Adil Kabylda",
      "Almaz Khabibrakhmanov",
      "Alexandre Tkatchenko"
    ],
    "abstract": "Van der Waals (vdW) interactions are essential for describing molecules and materials, from drug design and catalysis to battery applications. These omnipresent interactions must also be accurately included in machine-learned force fields. The many-body dispersion (MBD) method stands out as one of the most accurate and transferable approaches to capture vdW interactions, requiring only atomic $C_6$ coefficients and polarizabilities as input. We present MBD-ML, a pretrained message passing neural network that predicts these atomic properties directly from atomic structures. Through seamless integration with libMBD, our method enables the immediate calculation of MBD-inclusive total energies, forces, and stress tensors. By eliminating the need for intermediate electronic structure calculations, MBD-ML offers a practical and streamlined tool that simplifies the incorporation of state-of-the-art vdW interactions into any electronic structure code, as well as empirical and machine-learned force fields.",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "physics.chem-ph",
    "published": "2026-02-25T16:34:53Z",
    "updated": "2026-02-25T16:34:53Z",
    "url": "https://arxiv.org/abs/2602.22086v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22086v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Van der Waals (vdW) interactions are essential for describing molecules and materials, from drug design and catalysis to battery applications.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22073v1",
    "title": "AdaSpot: Spend Resolution Where It Matters for Precise Event Spotting",
    "authors": [
      "Artur Xarles",
      "Sergio Escalera",
      "Thomas B. Moeslund",
      "Albert Clapés"
    ],
    "abstract": "Precise Event Spotting aims to localize fast-paced actions or events in videos with high temporal precision, a key task for applications in sports analytics, robotics, and autonomous systems. Existing methods typically process all frames uniformly, overlooking the inherent spatio-temporal redundancy in video data. This leads to redundant computation on non-informative regions while limiting overall efficiency. To remain tractable, they often spatially downsample inputs, losing fine-grained details crucial for precise localization. To address these limitations, we propose \\textbf{AdaSpot}, a simple yet effective framework that processes low-resolution videos to extract global task-relevant features while adaptively selecting the most informative region-of-interest in each frame for high-resolution processing. The selection is performed via an unsupervised, task-aware strategy that maintains spatio-temporal consistency across frames and avoids the training instability of learnable alternatives. This design preserves essential fine-grained visual cues with a marginal computational overhead compared to low-resolution-only baselines, while remaining far more efficient than uniform high-resolution processing. Experiments on standard PES benchmarks demonstrate that \\textbf{AdaSpot} achieves state-of-the-art performance under strict evaluation metrics (\\eg, $+3.96$ and $+2.26$ mAP$@0$ frames on Tennis and FineDiving), while also maintaining strong results under looser metrics. Code is available at: \\href{https://github.com/arturxe2/AdaSpot}{https://github.com/arturxe2/AdaSpot}.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T16:24:48Z",
    "updated": "2026-02-25T16:24:48Z",
    "url": "https://arxiv.org/abs/2602.22073v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22073v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Precise Event Spotting aims to localize fast-paced actions or events in videos with high temporal precision, a key task for applications in sports analytics, robotics, and autonomous systems.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22072v1",
    "title": "Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models",
    "authors": [
      "Christian Nickel",
      "Laura Schrewe",
      "Florian Mai",
      "Lucie Flek"
    ],
    "abstract": "Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and examines the potential of Chain-of-Thought prompting (CoT) to enhance performance and explain the LLM's decision. We introduce a handcrafted, richly annotated ToM dataset, including classic and perturbed false belief tasks, the corresponding spaces of valid reasoning chains for correct task completion, subsequent reasoning faithfulness, task solutions, and propose metrics to evaluate reasoning chain correctness and to what extent final answers are faithful to reasoning traces of the generated CoT. We show a steep drop in ToM capabilities under task perturbation for all evaluated LLMs, questioning the notion of any robust form of ToM being present. While CoT prompting improves the ToM performance overall in a faithful manner, it surprisingly degrades accuracy for some perturbation classes, indicating that selective application is necessary.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-25T16:24:35Z",
    "updated": "2026-02-25T16:24:35Z",
    "url": "https://arxiv.org/abs/2602.22072v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22072v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Theory of Mind (ToM) refers to an agent's ability to model the internal states of others.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22070v1",
    "title": "Language Models Exhibit Inconsistent Biases Towards Algorithmic Agents and Human Experts",
    "authors": [
      "Jessica Y. Bo",
      "Lillio Mok",
      "Ashton Anderson"
    ],
    "abstract": "Large language models are increasingly used in decision-making tasks that require them to process information from a variety of sources, including both human experts and other algorithmic agents. How do LLMs weigh the information provided by these different sources? We consider the well-studied phenomenon of algorithm aversion, in which human decision-makers exhibit bias against predictions from algorithms. Drawing upon experimental paradigms from behavioural economics, we evaluate how eightdifferent LLMs delegate decision-making tasks when the delegatee is framed as a human expert or an algorithmic agent. To be inclusive of different evaluation formats, we conduct our study with two task presentations: stated preferences, modeled through direct queries about trust towards either agent, and revealed preferences, modeled through providing in-context examples of the performance of both agents. When prompted to rate the trustworthiness of human experts and algorithms across diverse tasks, LLMs give higher ratings to the human expert, which correlates with prior results from human respondents. However, when shown the performance of a human expert and an algorithm and asked to place an incentivized bet between the two, LLMs disproportionately choose the algorithm, even when it performs demonstrably worse. These discrepant results suggest that LLMs may encode inconsistent biases towards humans and algorithms, which need to be carefully considered when they are deployed in high-stakes scenarios. Furthermore, we discuss the sensitivity of LLMs to task presentation formats that should be broadly scrutinized in evaluation robustness for AI safety.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-25T16:18:28Z",
    "updated": "2026-02-25T16:18:28Z",
    "url": "https://arxiv.org/abs/2602.22070v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22070v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Large language models are increasingly used in decision-making tasks that require them to process information from a variety of sources, including both human experts and other algorithmic agents.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22066v1",
    "title": "DualWeaver: Synergistic Feature Weaving Surrogates for Multivariate Forecasting with Univariate Time Series Foundation Models",
    "authors": [
      "Jinpeng Li",
      "Zhongyi Pei",
      "Huaze Xue",
      "Bojian Zheng",
      "Chen Wang",
      "Jianmin Wang"
    ],
    "abstract": "Time-series foundation models (TSFMs) have achieved strong univariate forecasting through large-scale pre-training, yet effectively extending this success to multivariate forecasting remains challenging. To address this, we propose DualWeaver, a novel framework that adapts univariate TSFMs (Uni-TSFMs) for multivariate forecasting by using a pair of learnable, structurally symmetric surrogate series. Generated by a shared auxiliary feature-fusion module that captures cross-variable dependencies, these surrogates are mapped to TSFM-compatible series via the forecasting objective. The symmetric structure enables parameter-free reconstruction of final predictions directly from the surrogates, without additional parametric decoding. A theoretically grounded regularization term is further introduced to enhance robustness against adaptation collapse. Extensive experiments on diverse real-world datasets show that DualWeaver outperforms state-of-the-art multivariate forecasters in both accuracy and stability. We release the code at https://github.com/li-jinpeng/DualWeaver.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-25T16:13:12Z",
    "updated": "2026-02-25T16:13:12Z",
    "url": "https://arxiv.org/abs/2602.22066v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22066v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Time-series foundation models (TSFMs) have achieved strong univariate forecasting through large-scale pre-training, yet effectively extending this success to multivariate forecasting remains...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22061v1",
    "title": "Learning Quantum Data Distribution via Chaotic Quantum Diffusion Model",
    "authors": [
      "Quoc Hoan Tran",
      "Koki Chinzei",
      "Yasuhiro Endo",
      "Hirotaka Oshima"
    ],
    "abstract": "Generative models for quantum data pose significant challenges but hold immense potential in fields such as chemoinformatics and quantum physics. Quantum denoising diffusion probabilistic models (QuDDPMs) enable efficient learning of quantum data distributions by progressively scrambling and denoising quantum states; however, existing implementations typically rely on circuit-based random unitary dynamics that can be costly to realize and sensitive to control imperfections, particularly on analog quantum hardware. We propose the chaotic quantum diffusion model, a framework that generates projected ensembles via chaotic Hamiltonian time evolution, providing a flexible and hardware-compatible diffusion mechanism. Requiring only global, time-independent control, our approach substantially reduces implementation overhead across diverse analog quantum platforms while achieving accuracy comparable to QuDDPMs. This method improves trainability and robustness, broadening the applicability of quantum generative modeling.",
    "categories": [
      "quant-ph",
      "cs.LG",
      "nlin.CD"
    ],
    "primary_category": "quant-ph",
    "published": "2026-02-25T16:09:50Z",
    "updated": "2026-02-25T16:09:50Z",
    "url": "https://arxiv.org/abs/2602.22061v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22061v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Generative models for quantum data pose significant challenges but hold immense potential in fields such as chemoinformatics and quantum physics.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22059v1",
    "title": "NESTOR: A Nested MOE-based Neural Operator for Large-Scale PDE Pre-Training",
    "authors": [
      "Dengdi Sun",
      "Xiaoya Zhou",
      "Xiao Wang",
      "Hao Si",
      "Wanli Lyu",
      "Jin Tang",
      "Bin Luo"
    ],
    "abstract": "Neural operators have emerged as an efficient paradigm for solving PDEs, overcoming the limitations of traditional numerical methods and significantly improving computational efficiency. However, due to the diversity and complexity of PDE systems, existing neural operators typically rely on a single network architecture, which limits their capacity to fully capture heterogeneous features and complex system dependencies. This constraint poses a bottleneck for large-scale PDE pre-training based on neural operators. To address these challenges, we propose a large-scale PDE pre-trained neural operator based on a nested Mixture-of-Experts (MoE) framework. In particular, the image-level MoE is designed to capture global dependencies, while the token-level Sub-MoE focuses on local dependencies. Our model can selectively activate the most suitable expert networks for a given input, thereby enhancing generalization and transferability. We conduct large-scale pre-training on twelve PDE datasets from diverse sources and successfully transfer the model to downstream tasks. Extensive experiments demonstrate the effectiveness of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-25T16:08:46Z",
    "updated": "2026-02-25T16:08:46Z",
    "url": "https://arxiv.org/abs/2602.22059v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22059v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Neural operators have emerged as an efficient paradigm for solving PDEs, overcoming the limitations of traditional numerical methods and significantly improving computational efficiency.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22056v1",
    "title": "FlowCorrect: Efficient Interactive Correction of Generative Flow Policies for Robotic Manipulation",
    "authors": [
      "Edgar Welte",
      "Yitian Shi",
      "Rosa Wolf",
      "Maximillian Gilles",
      "Rania Rayyes"
    ],
    "abstract": "Generative manipulation policies can fail catastrophically under deployment-time distribution shift, yet many failures are near-misses: the robot reaches almost-correct poses and would succeed with a small corrective motion. We present FlowCorrect, a deployment-time correction framework that converts near-miss failures into successes using sparse human nudges, without full policy retraining. During execution, a human provides brief corrective pose nudges via a lightweight VR interface. FlowCorrect uses these sparse corrections to locally adapt the policy, improving actions without retraining the backbone while preserving the model performance on previously learned scenarios. We evaluate on a real-world robot across three tabletop tasks: pick-and-place, pouring, and cup uprighting. With a low correction budget, FlowCorrect improves success on hard cases by 85\\% while preserving performance on previously solved scenarios. The results demonstrate clearly that FlowCorrect learns only with very few demonstrations and enables fast and sample-efficient incremental, human-in-the-loop corrections of generative visuomotor policies at deployment time in real-world robotics.",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "published": "2026-02-25T16:06:49Z",
    "updated": "2026-02-25T16:06:49Z",
    "url": "https://arxiv.org/abs/2602.22056v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22056v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Generative manipulation policies can fail catastrophically under deployment-time distribution shift, yet many failures are near-misses: the robot reaches almost-correct poses and would succeed...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.22055v1",
    "title": "Physics-Informed Machine Learning for Vessel Shaft Power and Fuel Consumption Prediction: Interpretable KAN-based Approach",
    "authors": [
      "Hamza Haruna Mohammed",
      "Dusica Marijan",
      "Arnbjørn Maressa"
    ],
    "abstract": "Accurate prediction of shaft rotational speed, shaft power, and fuel consumption is crucial for enhancing operational efficiency and sustainability in maritime transportation. Conventional physics-based models provide interpretability but struggle with real-world variability, while purely data-driven approaches achieve accuracy at the expense of physical plausibility. This paper introduces a Physics-Informed Kolmogorov-Arnold Network (PI-KAN), a hybrid method that integrates interpretable univariate feature transformations with a physics-informed loss function and a leakage-free chained prediction pipeline. Using operational and environmental data from five cargo vessels, PI-KAN consistently outperforms the traditional polynomial method and neural network baselines. The model achieves the lowest mean absolute error (MAE) and root mean squared error (RMSE), and the highest coefficient of determination (R^2) for shaft power and fuel consumption across all vessels, while maintaining physically consistent behavior. Interpretability analysis reveals rediscovery of domain-consistent dependencies, such as cubic-like speed-power relationships and cosine-like wave and wind effects. These results demonstrate that PI-KAN achieves both predictive accuracy and interpretability, offering a robust tool for vessel performance monitoring and decision support in operational settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-25T16:06:28Z",
    "updated": "2026-02-25T16:06:28Z",
    "url": "https://arxiv.org/abs/2602.22055v1",
    "pdf_url": "https://arxiv.org/pdf/2602.22055v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Accurate prediction of shaft rotational speed, shaft power, and fuel consumption is crucial for enhancing operational efficiency and sustainability in maritime transportation.",
    "keyword_matches": []
  }
]