[
  {
    "arxiv_id": "2602.23271v1",
    "title": "Evaluating Stochasticity in Deep Research Agents",
    "authors": [
      "Haotian Zhai",
      "Elias Stengel-Eskin",
      "Pratik Patil",
      "Liu Leqi"
    ],
    "abstract": "Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and scientific discovery. Despite recent improvements in research quality (e.g., outcome accuracy when ground truth is available), DRA system design often overlooks a critical barrier to real-world deployment: stochasticity. Under identical queries, repeated executions of DRAs can exhibit substantial variability in terms of research outcome, findings, and citations. In this paper, we formalize the study of stochasticity in DRAs by modeling them as information acquisition Markov Decision Processes. We introduce an evaluation framework that quantifies variance in the system and identify three sources of it: information acquisition, information compression, and inference. Through controlled experiments, we investigate how stochasticity from these modules across different decision steps influences the variance of DRA outputs. Our results show that reducing stochasticity can improve research output quality, with inference and early-stage stochasticity contributing the most to DRA output variance. Based on these findings, we propose strategies for mitigating stochasticity while maintaining output quality via structured output and ensemble-based query generation. Our experiments on DeepSearchQA show that our proposed mitigation methods reduce average stochasticity by 22% while maintaining high research quality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T17:46:42Z",
    "updated": "2026-02-26T17:46:42Z",
    "url": "https://arxiv.org/abs/2602.23271v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23271v1",
    "relevance_score": 20.0,
    "display_category": "LLMs & Agents",
    "summary": "Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and...",
    "keyword_matches": [
      "RAG",
      "agentic"
    ]
  },
  {
    "arxiv_id": "2602.23258v1",
    "title": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning",
    "authors": [
      "Yutong Wang",
      "Siyuan Xiong",
      "Xuebo Liu",
      "Wenkang Zhou",
      "Liang Ding",
      "Miao Zhang",
      "Min Zhang"
    ],
    "abstract": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/AgentDropoutV2.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T17:31:43Z",
    "updated": "2026-02-26T17:31:43Z",
    "url": "https://arxiv.org/abs/2602.23258v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23258v1",
    "relevance_score": 20.0,
    "display_category": "LLMs & Agents",
    "summary": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants.",
    "keyword_matches": [
      "RAG",
      "multi-agent"
    ]
  },
  {
    "arxiv_id": "2602.23234v1",
    "title": "Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments",
    "authors": [
      "Evangelia Christakopoulou",
      "Vivekkumar Patel",
      "Hemanth Velaga",
      "Sandip Gaikwad"
    ],
    "abstract": "Large-scale commercial search systems optimize for relevance to drive successful sessions that help users find what they are looking for. To maximize relevance, we leverage two complementary objectives: behavioral relevance (results users tend to click or download) and textual relevance (a result's semantic fit to the query). A persistent challenge is the scarcity of expert-provided textual relevance labels relative to abundant behavioral relevance labels. We first address this by systematically evaluating LLM configurations, finding that a specialized, fine-tuned model significantly outperforms a much larger pre-trained one in providing highly relevant labels. Using this optimal model as a force multiplier, we generate millions of textual relevance labels to overcome the data scarcity. We show that augmenting our production ranker with these textual relevance labels leads to a significant outward shift of the Pareto frontier: offline NDCG improves for behavioral relevance while simultaneously increasing for textual relevance. These offline gains were validated by a worldwide A/B test on the App Store ranker, which demonstrated a statistically significant +0.24% increase in conversion rate, with the most substantial performance gains occurring in tail queries, where the new textual relevance labels provide a robust signal in the absence of reliable behavioral relevance labels.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "published": "2026-02-26T17:11:26Z",
    "updated": "2026-02-26T17:11:26Z",
    "url": "https://arxiv.org/abs/2602.23234v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23234v1",
    "relevance_score": 20.0,
    "display_category": "Retrieval & RAG",
    "summary": "Large-scale commercial search systems optimize for relevance to drive successful sessions that help users find what they are looking for.",
    "keyword_matches": [
      "Pareto",
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23360v1",
    "title": "Model Agreement via Anchoring",
    "authors": [
      "Eric Eaton",
      "Surbhi Goel",
      "Marcel Hussing",
      "Michael Kearns",
      "Aaron Roth",
      "Sikata Bela Sengupta",
      "Jessica Sorrell"
    ],
    "abstract": "Numerous lines of aim to control $\\textit{model disagreement}$ -- the extent to which two machine learning models disagree in their predictions. We adopt a simple and standard notion of model disagreement in real-valued prediction problems, namely the expected squared difference in predictions between two models trained on independent samples, without any coordination of the training processes. We would like to be able to drive disagreement to zero with some natural parameter(s) of the training procedure using analyses that can be applied to existing training methodologies. We develop a simple general technique for proving bounds on independent model disagreement based on $\\textit{anchoring}$ to the average of two models within the analysis. We then apply this technique to prove disagreement bounds for four commonly used machine learning algorithms: (1) stacked aggregation over an arbitrary model class (where disagreement is driven to 0 with the number of models $k$ being stacked) (2) gradient boosting (where disagreement is driven to 0 with the number of iterations $k$) (3) neural network training with architecture search (where disagreement is driven to 0 with the size $n$ of the architecture being optimized over) and (4) regression tree training over all regression trees of fixed depth (where disagreement is driven to 0 with the depth $d$ of the tree architecture). For clarity, we work out our initial bounds in the setting of one-dimensional regression with squared error loss -- but then show that all of our results generalize to multi-dimensional regression with any strongly convex loss.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T18:59:32Z",
    "updated": "2026-02-26T18:59:32Z",
    "url": "https://arxiv.org/abs/2602.23360v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23360v1",
    "relevance_score": 10.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Numerous lines of aim to control $\\textit{model disagreement}$ -- the extent to which two machine learning models disagree in their predictions.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23353v1",
    "title": "SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport",
    "authors": [
      "Simon Roschmann",
      "Paul Krzakala",
      "Sonia Mazelet",
      "Quentin Bouniot",
      "Zeynep Akata"
    ],
    "abstract": "The Platonic Representation Hypothesis posits that neural networks trained on different modalities converge toward a shared statistical model of the world. Recent work exploits this convergence by aligning frozen pretrained vision and language models with lightweight alignment layers, but typically relies on contrastive losses and millions of paired samples. In this work, we ask whether meaningful alignment can be achieved with substantially less supervision. We introduce a semi-supervised setting in which pretrained unimodal encoders are aligned using a small number of image-text pairs together with large amounts of unpaired data. To address this challenge, we propose SOTAlign, a two-stage framework that first recovers a coarse shared geometry from limited paired data using a linear teacher, then refines the alignment on unpaired samples via an optimal-transport-based divergence that transfers relational structure without overconstraining the target space. Unlike existing semi-supervised methods, SOTAlign effectively leverages unpaired images and text, learning robust joint embeddings across datasets and encoder pairs, and significantly outperforming supervised and semi-supervised baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T18:55:06Z",
    "updated": "2026-02-26T18:55:06Z",
    "url": "https://arxiv.org/abs/2602.23353v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23353v1",
    "relevance_score": 10.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "The Platonic Representation Hypothesis posits that neural networks trained on different modalities converge toward a shared statistical model of the world.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23351v1",
    "title": "Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning",
    "authors": [
      "Amita Kamath",
      "Jack Hessel",
      "Khyathi Chandu",
      "Jena D. Hwang",
      "Kai-Wei Chang",
      "Ranjay Krishna"
    ],
    "abstract": "The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse. We posit that this behavior stems from a reporting bias in their training data. That is, how people communicate about visual content by default omits tacit information needed to supervise some types of reasoning; e.g., \"at the game today!\" is a more likely caption than \"a photo of 37 people standing behind a field\". We investigate the data underlying the popular VLMs OpenCLIP, LLaVA-1.5 and Molmo through the lens of theories from pragmatics, and find that reporting bias results in insufficient representation of four reasoning skills (spatial, temporal, negation, and counting), despite the corpora being of web-scale, and/or synthetically generated. With a set of curated benchmarks, we demonstrate that: (i) VLMs perform poorly on the aforementioned types of reasoning suppressed in the training data by reporting bias; (ii) contrary to popular belief, scaling data size, model size, and to multiple languages does not result in emergence of these skills by default; but, promisingly, (iii) incorporating annotations specifically collected to obtain tacit information is effective. Our findings highlight the need for more intentional training data curation methods, rather than counting on scale for emergence of reasoning capabilities.",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-26T18:54:06Z",
    "updated": "2026-02-26T18:54:06Z",
    "url": "https://arxiv.org/abs/2602.23351v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23351v1",
    "relevance_score": 10.0,
    "display_category": "LLMs & Agents",
    "summary": "The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23330v1",
    "title": "Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks",
    "authors": [
      "Kunihiro Miyazaki",
      "Takanobu Kawahara",
      "Stephen Roberts",
      "Stefan Zohren"
    ],
    "abstract": "The advancement of large language models (LLMs) has accelerated the development of autonomous financial trading systems. While mainstream approaches deploy multi-agent systems mimicking analyst and manager roles, they often rely on abstract instructions that overlook the intricacies of real-world workflows, which can lead to degraded inference performance and less transparent decision-making. Therefore, we propose a multi-agent LLM trading framework that explicitly decomposes investment analysis into fine-grained tasks, rather than providing coarse-grained instructions. We evaluate the proposed framework using Japanese stock data, including prices, financial statements, news, and macro information, under a leakage-controlled backtesting setting. Experimental results show that fine-grained task decomposition significantly improves risk-adjusted returns compared to conventional coarse-grained designs. Crucially, further analysis of intermediate agent outputs suggests that alignment between analytical outputs and downstream decision preferences is a critical driver of system performance. Moreover, we conduct standard portfolio optimization, exploiting low correlation with the stock index and the variance of each system's output. This approach achieves superior performance. These findings contribute to the design of agent structure and task configuration when applying LLM agents to trading systems in practical settings.",
    "categories": [
      "cs.AI",
      "q-fin.TR"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T18:37:36Z",
    "updated": "2026-02-26T18:37:36Z",
    "url": "https://arxiv.org/abs/2602.23330v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23330v1",
    "relevance_score": 10.0,
    "display_category": "LLMs & Agents",
    "summary": "The advancement of large language models (LLMs) has accelerated the development of autonomous financial trading systems.",
    "keyword_matches": [
      "multi-agent"
    ]
  },
  {
    "arxiv_id": "2602.23315v1",
    "title": "Invariant Transformation and Resampling based Epistemic-Uncertainty Reduction",
    "authors": [
      "Sha Hu"
    ],
    "abstract": "An artificial intelligence (AI) model can be viewed as a function that maps inputs to outputs in high-dimensional spaces. Once designed and well trained, the AI model is applied for inference. However, even optimized AI models can produce inference errors due to aleatoric and epistemic uncertainties. Interestingly, we observed that when inferring multiple samples based on invariant transformations of an input, inference errors can show partial independences due to epistemic uncertainty. Leveraging this insight, we propose a \"resampling\" based inferencing that applies to a trained AI model with multiple transformed versions of an input, and aggregates inference outputs to a more accurate result. This approach has the potential to improve inference accuracy and offers a strategy for balancing model size and performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T18:22:40Z",
    "updated": "2026-02-26T18:22:40Z",
    "url": "https://arxiv.org/abs/2602.23315v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23315v1",
    "relevance_score": 10.0,
    "display_category": "Retrieval & RAG",
    "summary": "An artificial intelligence (AI) model can be viewed as a function that maps inputs to outputs in high-dimensional spaces.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23306v1",
    "title": "ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding",
    "authors": [
      "Yiran Guan",
      "Sifan Tu",
      "Dingkang Liang",
      "Linghao Zhu",
      "Jianzhong Ju",
      "Zhenbo Luo",
      "Jian Luan",
      "Yuliang Liu",
      "Xiang Bai"
    ],
    "abstract": "Omni-modal reasoning is essential for intelligent systems to understand and draw inferences from diverse data sources. While existing omni-modal large language models (OLLM) excel at perceiving diverse modalities, they lack the complex reasoning abilities of recent large reasoning models (LRM). However, enhancing the reasoning ability of OLLMs through additional training presents significant challenges, including the need for high-quality data, task-specific adaptation, and substantial computational costs. To address these limitations, we propose ThinkOmni, a training-free and data-free framework that lifts textual reasoning to omni-modal scenarios. ThinkOmni introduces two key components: 1) LRM-as-a-Guide, which leverages off-the-shelf LRMs to guide the OLLM decoding process; 2) Stepwise Contrastive Scaling, which adaptively balances perception and reasoning signals without manual hyperparameter tuning. Experiments on six multi-modal reasoning benchmarks demonstrate that ThinkOmni consistently delivers performance improvements, with main results achieving 70.2 on MathVista and 75.5 on MMAU. Overall, ThinkOmni offers a flexible and generalizable solution for omni-modal reasoning and provides new insights into the generalization and application of reasoning capabilities.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:10:41Z",
    "updated": "2026-02-26T18:10:41Z",
    "url": "https://arxiv.org/abs/2602.23306v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23306v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Omni-modal reasoning is essential for intelligent systems to understand and draw inferences from diverse data sources.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23300v1",
    "title": "A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations",
    "authors": [
      "Soumya Dutta",
      "Smruthi Balaji",
      "Sriram Ganapathy"
    ],
    "abstract": "Emotion Recognition in Conversations (ERC) presents unique challenges, requiring models to capture the temporal flow of multi-turn dialogues and to effectively integrate cues from multiple modalities. We propose Mixture of Speech-Text Experts for Recognition of Emotions (MiSTER-E), a modular Mixture-of-Experts (MoE) framework designed to decouple two core challenges in ERC: modality-specific context modeling and multimodal information fusion. MiSTER-E leverages large language models (LLMs) fine-tuned for both speech and text to provide rich utterance-level embeddings, which are then enhanced through a convolutional-recurrent context modeling layer. The system integrates predictions from three experts-speech-only, text-only, and cross-modal-using a learned gating mechanism that dynamically weighs their outputs. To further encourage consistency and alignment across modalities, we introduce a supervised contrastive loss between paired speech-text representations and a KL-divergence-based regulariza-tion across expert predictions. Importantly, MiSTER-E does not rely on speaker identity at any stage. Experiments on three benchmark datasets-IEMOCAP, MELD, and MOSI-show that our proposal achieves 70.9%, 69.5%, and 87.9% weighted F1-scores respectively, outperforming several baseline speech-text ERC systems. We also provide various ablations to highlight the contributions made in the proposed approach.",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-26T18:08:40Z",
    "updated": "2026-02-26T18:08:40Z",
    "url": "https://arxiv.org/abs/2602.23300v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23300v1",
    "relevance_score": 10.0,
    "display_category": "LLMs & Agents",
    "summary": "Emotion Recognition in Conversations (ERC) presents unique challenges, requiring models to capture the temporal flow of multi-turn dialogues and to effectively integrate cues from multiple modalities.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23297v1",
    "title": "PRIMA: Pre-training with Risk-integrated Image-Metadata Alignment for Medical Diagnosis via LLM",
    "authors": [
      "Yiqing Wang",
      "Chunming He",
      "Ming-Chen Lu",
      "Mercy Pawar",
      "Leslie Niziol",
      "Maria Woodward",
      "Sina Farsiu"
    ],
    "abstract": "Medical diagnosis requires the effective synthesis of visual manifestations and clinical metadata. However, existing methods often treat metadata as isolated tags, failing to exploit the rich semantic knowledge embedded in clinical descriptions. We propose PRIMA (Pre-training with Risk-integrated Image-Metadata Alignment), a framework that integrates domain-specific knowledge into multi-modal representation learning. We first curate an expert corpus of risk-disease correlations via Retrieval-Augmented Generation (RAG) to refine Clinical ModernBERT, embedding diagnostic priors into the text encoder. To bridge the modality gap, we introduce a dual-encoder pre-training strategy utilizing DINOv3 and our refined BERT, optimized by a suite of four complementary loss functions. These losses are designed to capture multi-granular semantic alignment and handle the ambiguity of clinical correlations through soft labels. Finally, we leverage Qwen-3 to fuse these aligned features for precise disease classification. Extensive experiments demonstrate that PRIMA effectively harmonizes pixel-level features with abstract clinical expertise, significantly outperforming other state-of-the-art methods. Notably, our framework achieves superior robustness without the need for massive data collection or exhaustive computational resources. Our code will be made public upon acceptance.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:07:52Z",
    "updated": "2026-02-26T18:07:52Z",
    "url": "https://arxiv.org/abs/2602.23297v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23297v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Medical diagnosis requires the effective synthesis of visual manifestations and clinical metadata.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23296v1",
    "title": "Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity",
    "authors": [
      "Quang-Huy Nguyen",
      "Jiaqi Wang",
      "Wei-Shinn Ku"
    ],
    "abstract": "Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classification and regression demonstrate that FedWQ-CP empirically maintains agent-wise and global coverage while producing the smallest prediction sets or intervals.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T18:07:45Z",
    "updated": "2026-02-26T18:07:45Z",
    "url": "https://arxiv.org/abs/2602.23296v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23296v1",
    "relevance_score": 10.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Federated learning (FL) faces challenges in uncertainty quantification (UQ).",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23295v1",
    "title": "ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation",
    "authors": [
      "Ayush Roy",
      "Wei-Yang Alex Lee",
      "Rudrasis Chakraborty",
      "Vishnu Suresh Lokhande"
    ],
    "abstract": "In recent times, large datasets hinder efficient model training while also containing redundant concepts. Dataset distillation aims to synthesize compact datasets that preserve the knowledge of large-scale training sets while drastically reducing storage and computation. Recent advances in diffusion models have enabled training-free distillation by leveraging pre-trained generative priors; however, existing guidance strategies remain limited. Current score-based methods either perform unguided denoising or rely on simple mode-based guidance toward instance prototype centroids (IPC centroids), which often are rudimentary and suboptimal. We propose Manifold-Guided Distillation (ManifoldGD), a training-free diffusion-based framework that integrates manifold consistent guidance at every denoising timestep. Our method employs IPCs computed via a hierarchical, divisive clustering of VAE latent features, yielding a multi-scale coreset of IPCs that captures both coarse semantic modes and fine intra-class variability. Using a local neighborhood of the extracted IPC centroids, we create the latent manifold for each diffusion denoising timestep. At each denoising step, we project the mode-alignment vector onto the local tangent space of the estimated latent manifold, thus constraining the generation trajectory to remain manifold-faithful while preserving semantic consistency. This formulation improves representativeness, diversity, and image fidelity without requiring any model retraining. Empirical results demonstrate consistent gains over existing training-free and training-based baselines in terms of FID, l2 distance among real and synthetic dataset embeddings, and classification accuracy, establishing ManifoldGD as the first geometry-aware training-free data distillation framework.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:07:10Z",
    "updated": "2026-02-26T18:07:10Z",
    "url": "https://arxiv.org/abs/2602.23295v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23295v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "In recent times, large datasets hinder efficient model training while also containing redundant concepts.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23280v1",
    "title": "Physics Informed Viscous Value Representations",
    "authors": [
      "Hrishikesh Viswanath",
      "Juanwu Lu",
      "S. Talha Bukhari",
      "Damon Conover",
      "Ziran Wang",
      "Aniket Bera"
    ],
    "abstract": "Offline goal-conditioned reinforcement learning (GCRL) learns goal-conditioned policies from static pre-collected datasets. However, accurate value estimation remains a challenge due to the limited coverage of the state-action space. Recent physics-informed approaches have sought to address this by imposing physical and geometric constraints on the value function through regularization defined over first-order partial differential equations (PDEs), such as the Eikonal equation. However, these formulations can often be ill-posed in complex, high-dimensional environments. In this work, we propose a physics-informed regularization derived from the viscosity solution of the Hamilton-Jacobi-Bellman (HJB) equation. By providing a physics-based inductive bias, our approach grounds the learning process in optimal control theory, explicitly regularizing and bounding updates during value iterations. Furthermore, we leverage the Feynman-Kac theorem to recast the PDE solution as an expectation, enabling a tractable Monte Carlo estimation of the objective that avoids numerical instability in higher-order gradients. Experiments demonstrate that our method improves geometric consistency, making it broadly applicable to navigation and high-dimensional, complex manipulation tasks. Open-source codes are available at https://github.com/HrishikeshVish/phys-fk-value-GCRL.",
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T17:53:46Z",
    "updated": "2026-02-26T17:53:46Z",
    "url": "https://arxiv.org/abs/2602.23280v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23280v1",
    "relevance_score": 10.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Offline goal-conditioned reinforcement learning (GCRL) learns goal-conditioned policies from static pre-collected datasets.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23262v1",
    "title": "Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling",
    "authors": [
      "Jasmine Bayrooti",
      "Weiwei Kong",
      "Natalia Ponomareva",
      "Carlos Esteves",
      "Ameesh Makadia",
      "Amanda Prorok"
    ],
    "abstract": "Generative models trained on sensitive image datasets risk memorizing and reproducing individual training examples, making strong privacy guarantees essential. While differential privacy (DP) provides a principled framework for such guarantees, standard DP finetuning (e.g., with DP-SGD) often results in severe degradation of image quality, particularly in high-frequency textures, due to the indiscriminate addition of noise across all model parameters. In this work, we propose a spectral DP framework based on the hypothesis that the most privacy-sensitive portions of an image are often low-frequency components in the wavelet space (e.g., facial features and object shapes) while high-frequency components are largely generic and public. Based on this hypothesis, we propose the following two-stage framework for DP image generation with coarse image intermediaries: (1) DP finetune an autoregressive spectral image tokenizer model on the low-resolution wavelet coefficients of the sensitive images, and (2) perform high-resolution upsampling using a publicly pretrained super-resolution model. By restricting the privacy budget to the global structures of the image in the first stage, and leveraging the post-processing property of DP for detail refinement, we achieve promising trade-offs between privacy and utility. Experiments on the MS-COCO and MM-CelebA-HQ datasets show that our method generates images with improved quality and style capture relative to other leading DP image frameworks.",
    "categories": [
      "cs.CV",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T17:36:48Z",
    "updated": "2026-02-26T17:36:48Z",
    "url": "https://arxiv.org/abs/2602.23262v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23262v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "Generative models trained on sensitive image datasets risk memorizing and reproducing individual training examples, making strong privacy guarantees essential.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23259v1",
    "title": "Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving",
    "authors": [
      "Jiangxin Sun",
      "Feng Xue",
      "Teng Long",
      "Chang Liu",
      "Jian-Fang Hu",
      "Wei-Shi Zheng",
      "Nicu Sebe"
    ],
    "abstract": "With advances in imitation learning (IL) and large-scale driving datasets, end-to-end autonomous driving (E2E-AD) has made great progress recently. Currently, IL-based methods have become a mainstream paradigm: models rely on standard driving behaviors given by experts, and learn to minimize the discrepancy between their actions and expert actions. However, this objective of \"only driving like the expert\" suffers from limited generalization: when encountering rare or unseen long-tail scenarios outside the distribution of expert demonstrations, models tend to produce unsafe decisions in the absence of prior experience. This raises a fundamental question: Can an E2E-AD system make reliable decisions without any expert action supervision? Motivated by this, we propose a unified framework named Risk-aware World Model Predictive Control (RaWMPC) to address this generalization dilemma through robust control, without reliance on expert demonstrations. Practically, RaWMPC leverages a world model to predict the consequences of multiple candidate actions and selects low-risk actions through explicit risk evaluation. To endow the world model with the ability to predict the outcomes of risky driving behaviors, we design a risk-aware interaction strategy that systematically exposes the world model to hazardous behaviors, making catastrophic outcomes predictable and thus avoidable. Furthermore, to generate low-risk candidate actions at test time, we introduce a self-evaluation distillation method to distill riskavoidance capabilities from the well-trained world model into a generative action proposal network without any expert demonstration. Extensive experiments show that RaWMPC outperforms state-of-the-art methods in both in-distribution and out-of-distribution scenarios, while providing superior decision interpretability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T17:32:30Z",
    "updated": "2026-02-26T17:32:30Z",
    "url": "https://arxiv.org/abs/2602.23259v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23259v1",
    "relevance_score": 10.0,
    "display_category": "Computer Vision",
    "summary": "With advances in imitation learning (IL) and large-scale driving datasets, end-to-end autonomous driving (E2E-AD) has made great progress recently.",
    "keyword_matches": [
      "RAG"
    ]
  },
  {
    "arxiv_id": "2602.23363v1",
    "title": "MediX-R1: Open Ended Medical Reinforcement Learning",
    "authors": [
      "Sahal Shaji Mullappilly",
      "Mohammed Irfan Kurpath",
      "Omair Mohamed",
      "Mohamed Zidan",
      "Fahad Khan",
      "Salman Khan",
      "Rao Anwer",
      "Hisham Cholakkal"
    ],
    "abstract": "We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group Based RL and a composite reward tailored for medical reasoning: an LLM-based accuracy reward that judges semantic correctness with a strict YES/NO decision, a medical embedding-based semantic reward to capture paraphrases and terminology variants, and lightweight format and modality rewards that enforce interpretable reasoning and modality recognition. This multi-signal design provides stable, informative feedback for open-ended outputs where traditional verifiable or MCQ-only rewards fall short. To measure progress, we propose a unified evaluation framework for both text-only and image+text tasks that uses a Reference-based LLM-as-judge in place of brittle string-overlap metrics, capturing semantic correctness, reasoning, and contextual alignment. Despite using only $\\sim51$K instruction examples, MediX-R1 achieves excellent results across standard medical LLM (text-only) and VLM (image + text) benchmarks, outperforming strong open-source baselines and delivering particularly large gains on open-ended clinical tasks. Our results demonstrate that open-ended RL with comprehensive reward signals and LLM-based evaluation is a practical path toward reliable medical reasoning in multimodal models. Our trained models, curated datasets and source code are available at https://medix.cvmbzuai.com",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:59:46Z",
    "updated": "2026-02-26T18:59:46Z",
    "url": "https://arxiv.org/abs/2602.23363v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23363v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23361v1",
    "title": "VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale",
    "authors": [
      "Sven Elflein",
      "Ruilong Li",
      "Sérgio Agostinho",
      "Zan Gojcic",
      "Laura Leal-Taixé",
      "Qunjie Zhou",
      "Aljosa Osep"
    ],
    "abstract": "We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t. the number of input images. Our approach is built on the key insight that this bottleneck stems from the varying-length Key-Value (KV) space representation of scene geometry, which we distill into a fixed-size Multi-Layer Perceptron (MLP) via test-time training. VGG-T$^3$ (Visual Geometry Grounded Test Time Training) scales linearly w.r.t. the number of input views, similar to online models, and reconstructs a $1k$ image collection in just $54$ seconds, achieving a $11.6\\times$ speed-up over baselines that rely on softmax attention. Since our method retains global scene aggregation capability, our point map reconstruction error outperforming other linear-time methods by large margins. Finally, we demonstrate visual localization capabilities of our model by querying the scene representation with unseen images.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:59:33Z",
    "updated": "2026-02-26T18:59:33Z",
    "url": "https://arxiv.org/abs/2602.23361v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23361v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23359v1",
    "title": "SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation",
    "authors": [
      "Vaibhav Agrawal",
      "Rishubh Parihar",
      "Pradhaan Bhat",
      "Ravi Kiran Sarvadevabhatla",
      "R. Venkatesh Babu"
    ],
    "abstract": "We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation. It is essential for synthesizing partially occluded objects with depth-consistent geometry and scale. While existing methods can generate realistic scenes that follow input layouts, they often fail to model precise inter-object occlusions. We propose SeeThrough3D, a model for 3D layout conditioned generation that explicitly models occlusions. We introduce an occlusion-aware 3D scene representation (OSCR), where objects are depicted as translucent 3D boxes placed within a virtual environment and rendered from desired camera viewpoint. The transparency encodes hidden object regions, enabling the model to reason about occlusions, while the rendered viewpoint provides explicit camera control during generation. We condition a pretrained flow based text-to-image image generation model by introducing a set of visual tokens derived from our rendered 3D representation. Furthermore, we apply masked self-attention to accurately bind each object bounding box to its corresponding textual description, enabling accurate generation of multiple objects without object attribute mixing. To train the model, we construct a synthetic dataset with diverse multi-object scenes with strong inter-object occlusions. SeeThrough3D generalizes effectively to unseen object categories and enables precise 3D layout control with realistic occlusions and consistent camera control.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:59:05Z",
    "updated": "2026-02-26T18:59:05Z",
    "url": "https://arxiv.org/abs/2602.23359v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23359v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23358v1",
    "title": "A Dataset is Worth 1 MB",
    "authors": [
      "Elad Kimchi Shoshani",
      "Leeyam Gabay",
      "Yedid Hoshen"
    ],
    "abstract": "A dataset server must often distribute the same large payload to many clients, incurring massive communication costs. Since clients frequently operate on diverse hardware and software frameworks, transmitting a pre-trained model is often infeasible; instead, agents require raw data to train their own task-specific models locally. While dataset distillation attempts to compress training signals, current methods struggle to scale to high-resolution data and rarely achieve sufficiently small files. In this paper, we propose Pseudo-Labels as Data (PLADA), a method that completely eliminates pixel transmission. We assume agents are preloaded with a large, generic, unlabeled reference dataset (e.g., ImageNet-1K, ImageNet-21K) and communicate a new task by transmitting only the class labels for specific images. To address the distribution mismatch between the reference and target datasets, we introduce a pruning mechanism that filters the reference dataset to retain only the labels of the most semantically relevant images for the target task. This selection process simultaneously maximizes training efficiency and minimizes transmission payload. Experiments on 10 diverse datasets demonstrate that our approach can transfer task knowledge with a payload of less than 1 MB while retaining high classification accuracy, offering a promising solution for efficient dataset serving.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T18:59:03Z",
    "updated": "2026-02-26T18:59:03Z",
    "url": "https://arxiv.org/abs/2602.23358v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23358v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "A dataset server must often distribute the same large payload to many clients, incurring massive communication costs.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23357v1",
    "title": "Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training",
    "authors": [
      "Aheli Saha",
      "René Schuster",
      "Didier Stricker"
    ],
    "abstract": "Bio-inspired event cameras have recently attracted significant research due to their asynchronous and low-latency capabilities. These features provide a high dynamic range and significantly reduce motion blur. However, because of the novelty in the nature of their output signals, there is a gap in the variability of available data and a lack of extensive analysis of the parameters characterizing their signals. This paper addresses these issues by providing readers with an in-depth understanding of how intrinsic parameters affect the performance of a model trained on event data, specifically for object detection. We also use our findings to expand the capabilities of the downstream model towards sensor-agnostic robustness.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:57:52Z",
    "updated": "2026-02-26T18:57:52Z",
    "url": "https://arxiv.org/abs/2602.23357v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23357v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Bio-inspired event cameras have recently attracted significant research due to their asynchronous and low-latency capabilities.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23349v1",
    "title": "FlashOptim: Optimizers for Memory Efficient Training",
    "authors": [
      "Jose Javier Gonzalez Ortiz",
      "Abhay Gupta",
      "Chris Renard",
      "Davis Blalock"
    ],
    "abstract": "Standard mixed-precision training of neural networks requires many bytes of accelerator memory for each model parameter. These bytes reflect not just the parameter itself, but also its gradient and one or more optimizer state variables. With each of these values typically requiring 4 bytes, training even a 7 billion parameter model can be impractical for researchers with less than 100GB of accelerator memory. We introduce FlashOptim, a suite of optimizations that reduces per-parameter memory by over 50% while preserving model quality and API compatibility. Our approach introduces two key techniques. First, we improve master weight splitting by finding and exploiting a tight bound on its quantization error. Second, we design companding functions that greatly reduce the error in 8-bit optimizer state quantization. Together with 16-bit gradients, these techniques reduce AdamW memory from 16 bytes to 7 bytes per parameter, or 5 bytes with gradient release. They also cut model checkpoint sizes by more than half. Experiments with FlashOptim applied to SGD, AdamW, and Lion show no measurable quality degradation on any task from a collection of standard vision and language benchmarks, including Llama-3.1-8B finetuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T18:52:22Z",
    "updated": "2026-02-26T18:52:22Z",
    "url": "https://arxiv.org/abs/2602.23349v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23349v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Standard mixed-precision training of neural networks requires many bytes of accelerator memory for each model parameter.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23342v1",
    "title": "AlayaLaser: Efficient Index Layout and Search Strategy for Large-scale High-dimensional Vector Similarity Search",
    "authors": [
      "Weijian Chen",
      "Haotian Liu",
      "Yangshen Deng",
      "Long Xiang",
      "Liang Huang",
      "Gezi Li",
      "Bo Tang"
    ],
    "abstract": "On-disk graph-based approximate nearest neighbor search (ANNS) is essential for large-scale, high-dimensional vector retrieval, yet its performance is widely recognized to be limited by the prohibitive I/O costs. Interestingly, we observed that the performance of on-disk graph-based index systems is compute-bound, not I/O-bound, with the rising of the vector data dimensionality (e.g., hundreds or thousands). This insight uncovers a significant optimization opportunity: existing on-disk graph-based index systems universally target I/O reduction and largely overlook computational overhead, which leaves a substantial performance improvement space. In this work, we propose AlayaLaser, an efficient on-disk graph-based index system for large-scale high-dimensional vector similarity search. In particular, we first conduct performance analysis on existing on-disk graph-based index systems via the adapted roofline model, then we devise a novel on-disk data layout in AlayaLaser to effectively alleviate the compute-bound, which is revealed by the above roofline model analysis, by exploiting SIMD instructions on modern CPUs. We next design a suite of optimization techniques (e.g., degree-based node cache, cluster-based entry point selection, and early dispatch strategy) to further improve the performance of AlayaLaser. We last conduct extensive experimental studies on a wide range of large-scale high-dimensional vector datasets to verify the superiority of AlayaLaser. Specifically, AlayaLaser not only surpasses existing on-disk graph-based index systems but also matches or even exceeds the performance of in-memory index systems.",
    "categories": [
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "published": "2026-02-26T18:48:29Z",
    "updated": "2026-02-26T18:48:29Z",
    "url": "https://arxiv.org/abs/2602.23342v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23342v1",
    "relevance_score": 0.0,
    "display_category": "Retrieval & RAG",
    "summary": "On-disk graph-based approximate nearest neighbor search (ANNS) is essential for large-scale, high-dimensional vector retrieval, yet its performance is widely recognized to be limited by the...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23341v1",
    "title": "Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms",
    "authors": [
      "Alkis Kalavasis",
      "Anay Mehrotra",
      "Manolis Zampetakis",
      "Felix Zhou",
      "Ziyu Zhu"
    ],
    "abstract": "Coarse data arise when learners observe only partial information about samples; namely, a set containing the sample rather than its exact value. This occurs naturally through measurement rounding, sensor limitations, and lag in economic systems. We study Gaussian mean estimation from coarse data, where each true sample $x$ is drawn from a $d$-dimensional Gaussian distribution with identity covariance, but is revealed only through the set of a partition containing $x$. When the coarse samples, roughly speaking, have ``low'' information, the mean cannot be uniquely recovered from observed samples (i.e., the problem is not identifiable). Recent work by Fotakis, Kalavasis, Kontonis, and Tzamos [FKKT21] established that sample-efficient mean estimation is possible when the unknown mean is identifiable and the partition consists of only convex sets. Moreover, they showed that without convexity, mean estimation becomes NP-hard. However, two fundamental questions remained open: (1) When is the mean identifiable under convex partitions? (2) Is computationally efficient estimation possible under identifiability and convex partitions? This work resolves both questions. [...]",
    "categories": [
      "cs.LG",
      "cs.DS",
      "math.ST",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T18:47:06Z",
    "updated": "2026-02-26T18:47:06Z",
    "url": "https://arxiv.org/abs/2602.23341v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23341v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Coarse data arise when learners observe only partial information about samples; namely, a set containing the sample rather than its exact value.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23339v1",
    "title": "Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation?",
    "authors": [
      "Tilemachos Aravanis",
      "Vladan Stojnić",
      "Bill Psomas",
      "Nikos Komodakis",
      "Giorgos Tolias"
    ],
    "abstract": "Open-vocabulary segmentation (OVS) extends the zero-shot recognition capabilities of vision-language models (VLMs) to pixel-level prediction, enabling segmentation of arbitrary categories specified by text prompts. Despite recent progress, OVS lags behind fully supervised approaches due to two challenges: the coarse image-level supervision used to train VLMs and the semantic ambiguity of natural language. We address these limitations by introducing a few-shot setting that augments textual prompts with a support set of pixel-annotated images. Building on this, we propose a retrieval-augmented test-time adapter that learns a lightweight, per-image classifier by fusing textual and visual support features. Unlike prior methods relying on late, hand-crafted fusion, our approach performs learned, per-query fusion, achieving stronger synergy between modalities. The method supports continually expanding support sets, and applies to fine-grained tasks such as personalized segmentation. Experiments show that we significantly narrow the gap between zero-shot and supervised segmentation while preserving open-vocabulary ability.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:45:33Z",
    "updated": "2026-02-26T18:45:33Z",
    "url": "https://arxiv.org/abs/2602.23339v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23339v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Open-vocabulary segmentation (OVS) extends the zero-shot recognition capabilities of vision-language models (VLMs) to pixel-level prediction, enabling segmentation of arbitrary categories...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23336v1",
    "title": "Differentiable Zero-One Loss via Hypersimplex Projections",
    "authors": [
      "Camilo Gomez",
      "Pengyang Wang",
      "Liansheng Tang"
    ],
    "abstract": "Recent advances in machine learning have emphasized the integration of structured optimization components into end-to-end differentiable models, enabling richer inductive biases and tighter alignment with task-specific objectives. In this work, we introduce a novel differentiable approximation to the zero-one loss-long considered the gold standard for classification performance, yet incompatible with gradient-based optimization due to its non-differentiability. Our method constructs a smooth, order-preserving projection onto the n,k-dimensional hypersimplex through a constrained optimization framework, leading to a new operator we term Soft-Binary-Argmax. After deriving its mathematical properties, we show how its Jacobian can be efficiently computed and integrated into binary and multiclass learning systems. Empirically, our approach achieves significant improvements in generalization under large-batch training by imposing geometric consistency constraints on the output logits, thereby narrowing the performance gap traditionally observed in large-batch training.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T18:41:31Z",
    "updated": "2026-02-26T18:41:31Z",
    "url": "https://arxiv.org/abs/2602.23336v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23336v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Recent advances in machine learning have emphasized the integration of structured optimization components into end-to-end differentiable models, enabling richer inductive biases and tighter...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23335v1",
    "title": "Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset",
    "authors": [
      "Dany Haddad",
      "Dan Bareket",
      "Joseph Chee Chang",
      "Jay DeYoung",
      "Jena D. Hwang",
      "Uri Katz",
      "Mark Polak",
      "Sangho Suh",
      "Harshit Surana",
      "Aryeh Tiktinsky",
      "Shriya Atmakuri",
      "Jonathan Bragg",
      "Mike D'Arcy",
      "Sergey Feldman",
      "Amal Hassan-Ali",
      "Rubén Lozano",
      "Bodhisattwa Prasad Majumder",
      "Charles McGrady",
      "Amanpreet Singh",
      "Brooke Vlahos",
      "Yoav Goldberg",
      "Doug Downey"
    ],
    "abstract": "AI-powered scientific research tools are rapidly being integrated into research workflows, yet the field lacks a clear lens into how researchers use these systems in real-world settings. We present and analyze the Asta Interaction Dataset, a large-scale resource comprising over 200,000 user queries and interaction logs from two deployed tools (a literature discovery interface and a scientific question-answering interface) within an LLM-powered retrieval-augmented generation platform. Using this dataset, we characterize query patterns, engagement behaviors, and how usage evolves with experience. We find that users submit longer and more complex queries than in traditional search, and treat the system as a collaborative research partner, delegating tasks such as drafting content and identifying research gaps. Users treat generated responses as persistent artifacts, revisiting and navigating among outputs and cited evidence in non-linear ways. With experience, users issue more targeted queries and engage more deeply with supporting citations, although keyword-style queries persist even among experienced users. We release the anonymized dataset and analysis with a new query intent taxonomy to inform future designs of real-world AI research assistants and to support realistic evaluation.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.HC",
    "published": "2026-02-26T18:40:28Z",
    "updated": "2026-02-26T18:40:28Z",
    "url": "https://arxiv.org/abs/2602.23335v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23335v1",
    "relevance_score": 0.0,
    "display_category": "Retrieval & RAG",
    "summary": "AI-powered scientific research tools are rapidly being integrated into research workflows, yet the field lacks a clear lens into how researchers use these systems in real-world settings.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23334v1",
    "title": "Bitwise Systolic Array Architecture for Runtime-Reconfigurable Multi-precision Quantized Multiplication on Hardware Accelerators",
    "authors": [
      "Yuhao Liu",
      "Salim Ullah",
      "Akash Kumar"
    ],
    "abstract": "Neural network accelerators have been widely applied to edge devices for complex tasks like object tracking, image recognition, etc. Previous works have explored the quantization technologies in related lightweight accelerator designs to reduce hardware resource consumption. However, low precision leads to high accuracy loss in inference. Therefore, mixed-precision quantization becomes an alternative solution by applying different precision in different layers to trade off resource consumption and accuracy. Because regular designs for multiplication on hardware cannot support the precision reconfiguration for a multi-precision Quantized Neural Network (QNN) model in runtime, we propose a runtime reconfigurable multi-precision multi-channel bitwise systolic array design for QNN accelerators. We have implemented and evaluated our work on the Ultra96 FPGA platform. Results show that our work can achieve 1.3185 to 3.5671 times speedup in inferring mixed-precision models and has less critical path delay, supporting a higher clock frequency (250MHz).",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "published": "2026-02-26T18:40:02Z",
    "updated": "2026-02-26T18:40:02Z",
    "url": "https://arxiv.org/abs/2602.23334v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23334v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Neural network accelerators have been widely applied to edge devices for complex tasks like object tracking, image recognition, etc.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23331v1",
    "title": "Utilizing LLMs for Industrial Process Automation",
    "authors": [
      "Salim Fares"
    ],
    "abstract": "A growing number of publications address the best practices to use Large Language Models (LLMs) for software engineering in recent years. However, most of this work focuses on widely-used general purpose programming languages like Python due to their widespread usage training data. The utility of LLMs for software within the industrial process automation domain, with highly-specialized languages that are typically only used in proprietary contexts, remains underexplored. This research aims to utilize and integrate LLMs in the industrial development process, solving real-life programming tasks (e.g., generating a movement routine for a robotic arm) and accelerating the development cycles of manufacturing systems.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "published": "2026-02-26T18:38:00Z",
    "updated": "2026-02-26T18:38:00Z",
    "url": "https://arxiv.org/abs/2602.23331v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23331v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "A growing number of publications address the best practices to use Large Language Models (LLMs) for software engineering in recent years.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23329v1",
    "title": "LLM Novice Uplift on Dual-Use, In Silico Biology Tasks",
    "authors": [
      "Chen Bo Calvin Zhang",
      "Christina Q. Knight",
      "Nicholas Kruus",
      "Jason Hausenloy",
      "Pedro Medeiros",
      "Nathaniel Li",
      "Aiden Kim",
      "Yury Orlovskiy",
      "Coleman Breen",
      "Bryce Cai",
      "Jasper Götting",
      "Andrew Bo Liu",
      "Samira Nedungadi",
      "Paula Rodriguez",
      "Yannis Yiming He",
      "Mohamed Shaaban",
      "Zifan Wang",
      "Seth Donoughe",
      "Julian Michael"
    ],
    "abstract": "Large language models (LLMs) perform increasingly well on biology benchmarks, but it remains unclear whether they uplift novice users -- i.e., enable humans to perform better than with internet-only resources. This uncertainty is central to understanding both scientific acceleration and dual-use risk. We conducted a multi-model, multi-benchmark human uplift study comparing novices with LLM access versus internet-only access across eight biosecurity-relevant task sets. Participants worked on complex problems with ample time (up to 13 hours for the most involved tasks). We found that LLM access provided substantial uplift: novices with LLMs were 4.16 times more accurate than controls (95% CI [2.63, 6.87]). On four benchmarks with available expert baselines (internet-only), novices with LLMs outperformed experts on three of them. Perhaps surprisingly, standalone LLMs often exceeded LLM-assisted novices, indicating that users were not eliciting the strongest available contributions from the LLMs. Most participants (89.6%) reported little difficulty obtaining dual-use-relevant information despite safeguards. Overall, LLMs substantially uplift novices on biological tasks previously reserved for trained practitioners, underscoring the need for sustained, interactive uplift evaluations alongside traditional benchmarks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T18:37:23Z",
    "updated": "2026-02-26T18:37:23Z",
    "url": "https://arxiv.org/abs/2602.23329v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23329v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Large language models (LLMs) perform increasingly well on biology benchmarks, but it remains unclear whether they uplift novice users -- i.e., enable humans to perform better than with...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23321v1",
    "title": "Deep ensemble graph neural networks for probabilistic cosmic-ray direction and energy reconstruction in autonomous radio arrays",
    "authors": [
      "Arsène Ferrière",
      "Aurélien Benoit-Lévy",
      "Olivier Martineau-Huynh",
      "Matías Tueros"
    ],
    "abstract": "Using advanced machine learning techniques, we developed a method for reconstructing precisely the arrival direction and energy of ultra-high-energy cosmic rays from the voltage traces they induced on ground-based radio detector arrays. In our approach, triggered antennas are represented as a graph structure, which serves as input for a graph neural network (GNN). By incorporating physical knowledge into both the GNN architecture and the input data, we improve the precision and reduce the required size of the training set with respect to a fully data-driven approach. This method achieves an angular resolution of 0.092° and an electromagnetic energy reconstruction resolution of 16.4% on simulated data with realistic noise conditions. We also employ uncertainty estimation methods to enhance the reliability of our predictions, quantifying the confidence of the GNN's outputs and providing confidence intervals for both direction and energy reconstruction. Finally, we investigate strategies to verify the model's consistency and robustness under real life variations, with the goal of identifying scenarios in which predictions remain reliable despite domain shifts between simulation and reality.",
    "categories": [
      "astro-ph.IM",
      "cs.LG"
    ],
    "primary_category": "astro-ph.IM",
    "published": "2026-02-26T18:29:48Z",
    "updated": "2026-02-26T18:29:48Z",
    "url": "https://arxiv.org/abs/2602.23321v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23321v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Using advanced machine learning techniques, we developed a method for reconstructing precisely the arrival direction and energy of ultra-high-energy cosmic rays from the voltage traces they...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23320v1",
    "title": "ParamMem: Augmenting Language Agents with Parametric Reflective Memory",
    "authors": [
      "Tianjun Yao",
      "Yongqiang Chen",
      "Yujia Zheng",
      "Pan Li",
      "Zhiqiang Shen",
      "Kun Zhang"
    ],
    "abstract": "Self-reflection enables language agents to iteratively refine solutions, yet often produces repetitive outputs that limit reasoning performance. Recent studies have attempted to address this limitation through various approaches, among which increasing reflective diversity has shown promise. Our empirical analysis reveals a strong positive correlation between reflective diversity and task success, further motivating the need for diverse reflection signals. We introduce ParamMem, a parametric memory module that encodes cross-sample reflection patterns into model parameters, enabling diverse reflection generation through temperature-controlled sampling. Building on this module, we propose ParamAgent, a reflection-based agent framework that integrates parametric memory with episodic and cross-sample memory. Extensive experiments on code generation, mathematical reasoning, and multi-hop question answering demonstrate consistent improvements over state-of-the-art baselines. Further analysis reveals that ParamMem is sample-efficient, enables weak-to-strong transfer across model scales, and supports self-improvement without reliance on stronger external model, highlighting the potential of ParamMem as an effective component for enhancing language agents.",
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T18:28:04Z",
    "updated": "2026-02-26T18:28:04Z",
    "url": "https://arxiv.org/abs/2602.23320v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23320v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Self-reflection enables language agents to iteratively refine solutions, yet often produces repetitive outputs that limit reasoning performance.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23318v1",
    "title": "Generalized Rapid Action Value Estimation in Memory-Constrained Environments",
    "authors": [
      "Aloïs Rautureau",
      "Tristan Cazenave",
      "Éric Piette"
    ],
    "abstract": "Generalized Rapid Action Value Estimation (GRAVE) has been shown to be a strong variant within the Monte-Carlo Tree Search (MCTS) family of algorithms for General Game Playing (GGP). However, its reliance on storing additional win/visit statistics at each node makes its use impractical in memory-constrained environments, thereby limiting its applicability in practice. In this paper, we introduce the GRAVE2, GRAVER and GRAVER2 algorithms, which extend GRAVE through two-level search, node recycling, and a combination of both techniques, respectively. We show that these enhancements enable a drastic reduction in the number of stored nodes while matching the playing strength of GRAVE.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T18:25:59Z",
    "updated": "2026-02-26T18:25:59Z",
    "url": "https://arxiv.org/abs/2602.23318v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23318v1",
    "relevance_score": 0.0,
    "display_category": "Retrieval & RAG",
    "summary": "Generalized Rapid Action Value Estimation (GRAVE) has been shown to be a strong variant within the Monte-Carlo Tree Search (MCTS) family of algorithms for General Game Playing (GGP).",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23312v1",
    "title": "Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction",
    "authors": [
      "Rafael R. Baptista",
      "André de Lima Salgado",
      "Ricardo V. Godoy",
      "Marcelo Becker",
      "Thiago Boaventura",
      "Gustavo J. G. Lahr"
    ],
    "abstract": "Leader-follower interaction is an important paradigm in human-robot interaction (HRI). Yet, assigning roles in real time remains challenging for resource-constrained mobile and assistive robots. While large language models (LLMs) have shown promise for natural communication, their size and latency limit on-device deployment. Small language models (SLMs) offer a potential alternative, but their effectiveness for role classification in HRI has not been systematically evaluated. In this paper, we present a benchmark of SLMs for leader-follower communication, introducing a novel dataset derived from a published database and augmented with synthetic samples to capture interaction-specific dynamics. We investigate two adaptation strategies: prompt engineering and fine-tuning, studied under zero-shot and one-shot interaction modes, compared with an untrained baseline. Experiments with Qwen2.5-0.5B reveal that zero-shot fine-tuning achieves robust classification performance (86.66% accuracy) while maintaining low latency (22.2 ms per sample), significantly outperforming baseline and prompt-engineered approaches. However, results also indicate a performance degradation in one-shot modes, where increased context length challenges the model's architectural capacity. These findings demonstrate that fine-tuned SLMs provide an effective solution for direct role assignment, while highlighting critical trade-offs between dialogue complexity and classification reliability on the edge.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "eess.SY"
    ],
    "primary_category": "cs.HC",
    "published": "2026-02-26T18:20:26Z",
    "updated": "2026-02-26T18:20:26Z",
    "url": "https://arxiv.org/abs/2602.23312v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23312v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Leader-follower interaction is an important paradigm in human-robot interaction (HRI).",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23305v1",
    "title": "A Proper Scoring Rule for Virtual Staining",
    "authors": [
      "Samuel Tonks",
      "Steve Hood",
      "Ryan Musso",
      "Ceridwen Hopely",
      "Steve Titus",
      "Minh Doan",
      "Iain Styles",
      "Alexander Krull"
    ],
    "abstract": "Generative virtual staining (VS) models for high-throughput screening (HTS) can provide an estimated posterior distribution of possible biological feature values for each input and cell. However, when evaluating a VS model, the true posterior is unavailable. Existing evaluation protocols only check the accuracy of the marginal distribution over the dataset rather than the predicted posteriors. We introduce information gain (IG) as a cell-wise evaluation framework that enables direct assessment of predicted posteriors. IG is a strictly proper scoring rule and comes with a sound theoretical motivation allowing for interpretability, and for comparing results across models and features. We evaluate diffusion- and GAN-based models on an extensive HTS dataset using IG and other metrics and show that IG can reveal substantial performance differences other metrics cannot.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T18:09:49Z",
    "updated": "2026-02-26T18:09:49Z",
    "url": "https://arxiv.org/abs/2602.23305v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23305v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Generative virtual staining (VS) models for high-throughput screening (HTS) can provide an estimated posterior distribution of possible biological feature values for each input and cell.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23303v1",
    "title": "Inferential Mechanics Part 1: Causal Mechanistic Theories of Machine Learning in Chemical Biology with Implications",
    "authors": [
      "Ilya Balabin",
      "Thomas M. Kaiser"
    ],
    "abstract": "Machine learning techniques are now routinely encountered in research laboratories across the globe. Impressive progress has been made through ML and AI techniques with regards to large data set processing. This progress has increased the ability of the experimenter to digest data and make novel predictions regarding phenomena of interest. However, machine learning predictors generated from data sets taken from the natural sciences are often treated as black boxes which are used broadly and generally without detailed consideration of the causal structure of the data set of interest. Work has been attempted to bring causality into discussions of machine learning models of natural phenomena; however, a firm and unified theoretical treatment is lacking. This series of three papers explores the union of chemical theory, biological theory, probability theory and causality that will correct current causal flaws of machine learning in the natural sciences. This paper, Part 1 of the series, provides the formal framework of the foundational causal structure of phenomena in chemical biology and is extended to machine learning through the novel concept of focus, defined here as the ability of a machine learning algorithm to narrow down to a hidden underpinning mechanism in large data sets. Initial proof of these principles on a family of Akt inhibitors is also provided. The second paper containing Part 2 will provide a formal exploration of chemical similarity, and Part 3 will present extensive experimental evidence of how hidden causal structures weaken all machine learning in chemical biology. This series serves to establish for chemical biology a new kind of mathematical framework for modeling mechanisms in Nature without the need for the tools of reductionism: inferential mechanics.",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "published": "2026-02-26T18:09:16Z",
    "updated": "2026-02-26T18:09:16Z",
    "url": "https://arxiv.org/abs/2602.23303v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23303v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "Machine learning techniques are now routinely encountered in research laboratories across the globe.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23302v1",
    "title": "The logic of KM belief update is contained in the logic of AGM belief revision",
    "authors": [
      "Giacomo Bonanno"
    ],
    "abstract": "For each axiom of KM belief update we provide a corresponding axiom in a modal logic containing three modal operators: a unimodal belief operator $B$, a bimodal conditional operator $>$ and the unimodal necessity operator $\\square$. We then compare the resulting logic to the similar logic obtained from converting the AGM axioms of belief revision into modal axioms and show that the latter contains the former. Denoting the latter by $\\mathcal L_{AGM}$ and the former by $\\mathcal L_{KM}$ we show that every axiom of $\\mathcal L_{KM}$ is a theorem of $\\mathcal L_{AGM}$. Thus AGM belief revision can be seen as a special case of KM belief update. For the strong version of KM belief update we show that the difference between $\\mathcal L_{KM}$ and $\\mathcal L_{AGM}$ can be narrowed down to a single axiom, which deals exclusively with unsurprising information, that is, with formulas that were not initially disbelieved.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "math.LO"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T18:09:02Z",
    "updated": "2026-02-26T18:09:02Z",
    "url": "https://arxiv.org/abs/2602.23302v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23302v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "For each axiom of KM belief update we provide a corresponding axiom in a modal logic containing three modal operators: a unimodal belief operator $B$, a bimodal conditional operator $>$ and the...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23294v1",
    "title": "Towards Long-Form Spatio-Temporal Video Grounding",
    "authors": [
      "Xin Gu",
      "Bing Fan",
      "Jiali Yao",
      "Zhipeng Zhang",
      "Yan Huang",
      "Cheng Han",
      "Heng Fan",
      "Libo Zhang"
    ],
    "abstract": "In real scenarios, videos can span several minutes or even hours. However, existing research on spatio-temporal video grounding (STVG), given a textual query, mainly focuses on localizing targets in short videos of tens of seconds, typically less than one minute, which limits real-world applications. In this paper, we explore Long-Form STVG (LF-STVG), which aims to locate targets in long-term videos. Compared with short videos, long-term videos contain much longer temporal spans and more irrelevant information, making it difficult for existing STVG methods that process all frames at once. To address this challenge, we propose an AutoRegressive Transformer architecture for LF-STVG, termed ART-STVG. Unlike conventional STVG methods that require the entire video sequence to make predictions at once, ART-STVG treats the video as streaming input and processes frames sequentially, enabling efficient handling of long videos. To model spatio-temporal context, we design spatial and temporal memory banks and apply them to the decoders. Since memories from different moments are not always relevant to the current frame, we introduce simple yet effective memory selection strategies to provide more relevant information to the decoders, significantly improving performance. Furthermore, instead of parallel spatial and temporal localization, we propose a cascaded spatio-temporal design that connects the spatial decoder to the temporal decoder, allowing fine-grained spatial cues to assist complex temporal localization in long videos. Experiments on newly extended LF-STVG datasets show that ART-STVG significantly outperforms state-of-the-art methods, while achieving competitive performance on conventional short-form STVG.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:04:09Z",
    "updated": "2026-02-26T18:04:09Z",
    "url": "https://arxiv.org/abs/2602.23294v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23294v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "In real scenarios, videos can span several minutes or even hours.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23292v1",
    "title": "PGVMS: A Prompt-Guided Unified Framework for Virtual Multiplex IHC Staining with Pathological Semantic Learning",
    "authors": [
      "Fuqiang Chen",
      "Ranran Zhang",
      "Wanming Hu",
      "Deboch Eyob Abera",
      "Yue Peng",
      "Boyun Zheng",
      "Yiwen Sun",
      "Jing Cai",
      "Wenjian Qin"
    ],
    "abstract": "Immunohistochemical (IHC) staining enables precise molecular profiling of protein expression, with over 200 clinically available antibody-based tests in modern pathology. However, comprehensive IHC analysis is frequently limited by insufficient tissue quantities in small biopsies. Therefore, virtual multiplex staining emerges as an innovative solution to digitally transform H&E images into multiple IHC representations, yet current methods still face three critical challenges: (1) inadequate semantic guidance for multi-staining, (2) inconsistent distribution of immunochemistry staining, and (3) spatial misalignment across different stain modalities. To overcome these limitations, we present a prompt-guided framework for virtual multiplex IHC staining using only uniplex training data (PGVMS). Our framework introduces three key innovations corresponding to each challenge: First, an adaptive prompt guidance mechanism employing a pathological visual language model dynamically adjusts staining prompts to resolve semantic guidance limitations (Challenge 1). Second, our protein-aware learning strategy (PALS) maintains precise protein expression patterns by direct quantification and constraint of protein distributions (Challenge 2). Third, the prototype-consistent learning strategy (PCLS) establishes cross-image semantic interaction to correct spatial misalignments (Challenge 3).",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:03:24Z",
    "updated": "2026-02-26T18:03:24Z",
    "url": "https://arxiv.org/abs/2602.23292v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23292v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Immunohistochemical (IHC) staining enables precise molecular profiling of protein expression, with over 200 clinically available antibody-based tests in modern pathology.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23290v1",
    "title": "LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction",
    "authors": [
      "Zhengyang Wei",
      "Renzhi Jing",
      "Yiyi He",
      "Jenny Suckale"
    ],
    "abstract": "The accurate and automatic extraction of roads from satellite imagery is critical for applications in navigation and urban planning, significantly reducing the need for manual annotation. Many existing methods decompose this task into keypoint extraction and connectedness prediction, but often struggle to capture long-range dependencies and complex topologies. Here, we propose LineGraph2Road, a framework that improves connectedness prediction by formulating it as binary classification over edges in a constructed global but sparse Euclidean graph, where nodes are keypoints extracted from segmentation masks and edges connect node pairs within a predefined distance threshold, representing potential road segments. To better learn structural link representation, we transform the original graph into its corresponding line graph and apply a Graph Transformer on it for connectedness prediction. This formulation overcomes the limitations of endpoint-embedding fusion on set-isomorphic links, enabling rich link representations and effective relational reasoning over the global structure. Additionally, we introduce an overpass/underpass head to resolve multi-level crossings and a coupled NMS strategy to preserve critical connections. We evaluate LineGraph2Road on three benchmarks: City-scale, SpaceNet, and Global-scale, and show that it achieves state-of-the-art results on two key metrics, TOPO-F1 and APLS. It also captures fine visual details critical for real-world deployment. We will make our code publicly available.",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T18:02:44Z",
    "updated": "2026-02-26T18:02:44Z",
    "url": "https://arxiv.org/abs/2602.23290v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23290v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "The accurate and automatic extraction of roads from satellite imagery is critical for applications in navigation and urban planning, significantly reducing the need for manual annotation.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23286v1",
    "title": "SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables",
    "authors": [
      "Sungho Park",
      "Jueun Kim",
      "Wook-Shin Han"
    ],
    "abstract": "Real-world Table-Text question answering (QA) tasks require models that can reason across long text and source tables, traversing multiple hops and executing complex operations such as aggregation. Yet existing benchmarks are small, manually curated - and therefore error-prone - and contain shallow questions that seldom demand more than two hops or invoke aggregations, grouping, or other advanced analytical operations expressible in natural-language queries. We present SPARTA, an end-to-end construction framework that automatically generates large-scale Table-Text QA benchmarks with lightweight human validation, requiring only one quarter of the annotation time of HybridQA. The framework first constructs a reference fact database by enriching each source table with grounding tables whose tuples are atomic facts automatically extracted from the accompanying unstructured passages, then synthesizes nested queries whose number of nested predicates matches the desired hop count. To ensure that every SQL statement is executable and that its verbalization yields a fluent, human-sounding question, we propose two novel techniques: provenance-based refinement, which rewrites any syntactically valid query that returns a non-empty result, and realistic-structure enforcement, which confines generation to post-order traversals of the query graph. The resulting pipeline produces thousands of high-fidelity question-answer pairs covering aggregations, grouping, and deep multi-hop reasoning across text and tables. On SPARTA, state-of-the-art models that reach over 70 F1 on HybridQA or over 50 F1 on OTT-QA drop by more than 30 F1 points, exposing fundamental weaknesses in current cross-modal reasoning. Our benchmark, construction code, and baseline models are available at https://github.com/pshlego/SPARTA/tree/main.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-26T17:59:51Z",
    "updated": "2026-02-26T17:59:51Z",
    "url": "https://arxiv.org/abs/2602.23286v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23286v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Real-world Table-Text question answering (QA) tasks require models that can reason across long text and source tables, traversing multiple hops and executing complex operations such as aggregation.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23285v1",
    "title": "ODEBrain: Continuous-Time EEG Graph for Modeling Dynamic Brain Networks",
    "authors": [
      "Haohui Jia",
      "Zheng Chen",
      "Lingwei Zhu",
      "Rikuto Kotoge",
      "Jathurshan Pradeepkumar",
      "Yasuko Matsubara",
      "Jimeng Sun",
      "Yasushi Sakurai",
      "Takashi Matsubara"
    ],
    "abstract": "Modeling neural population dynamics is crucial for foundational neuroscientific research and various clinical applications. Conventional latent variable methods typically model continuous brain dynamics through discretizing time with recurrent architecture, which necessarily results in compounded cumulative prediction errors and failure of capturing instantaneous, nonlinear characteristics of EEGs. We propose ODEBRAIN, a Neural ODE latent dynamic forecasting framework to overcome these challenges by integrating spatio-temporal-frequency features into spectral graph nodes, followed by a Neural ODE modeling the continuous latent dynamics. Our design ensures that latent representations can capture stochastic variations of complex brain states at any given time point. Extensive experiments verify that ODEBRAIN can improve significantly over existing methods in forecasting EEG dynamics with enhanced robustness and generalization capabilities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T17:59:10Z",
    "updated": "2026-02-26T17:59:10Z",
    "url": "https://arxiv.org/abs/2602.23285v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23285v1",
    "relevance_score": 0.0,
    "display_category": "Retrieval & RAG",
    "summary": "Modeling neural population dynamics is crucial for foundational neuroscientific research and various clinical applications.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23277v1",
    "title": "Zeroth-Order Stackelberg Control in Combinatorial Congestion Games",
    "authors": [
      "Saeed Masiha",
      "Sepehr Elahi",
      "Negar Kiyavash",
      "Patrick Thiran"
    ],
    "abstract": "We study Stackelberg (leader--follower) tuning of network parameters (tolls, capacities, incentives) in combinatorial congestion games, where selfish users choose discrete routes (or other combinatorial strategies) and settle at a congestion equilibrium. The leader minimizes a system-level objective (e.g., total travel time) evaluated at equilibrium, but this objective is typically nonsmooth because the set of used strategies can change abruptly. We propose ZO-Stackelberg, which couples a projection-free Frank--Wolfe equilibrium solver with a zeroth-order outer update, avoiding differentiation through equilibria. We prove convergence to generalized Goldstein stationary points of the true equilibrium objective, with explicit dependence on the equilibrium approximation error, and analyze subsampled oracles: if an exact minimizer is sampled with probability $κ_m$, then the Frank--Wolfe error decays as $\\mathcal{O}(1/(κ_m T))$. We also propose stratified sampling as a practical way to avoid a vanishing $κ_m$ when the strategies that matter most for the Wardrop equilibrium concentrate in a few dominant combinatorial classes (e.g., short paths). Experiments on real-world networks demonstrate that our method achieves orders-of-magnitude speedups over a differentiation-based baseline while converging to follower equilibria.",
    "categories": [
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "published": "2026-02-26T17:52:08Z",
    "updated": "2026-02-26T17:52:08Z",
    "url": "https://arxiv.org/abs/2602.23277v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23277v1",
    "relevance_score": 0.0,
    "display_category": "Machine Learning & Deep Learning",
    "summary": "We study Stackelberg (leader--follower) tuning of network parameters (tolls, capacities, incentives) in combinatorial congestion games, where selfish users choose discrete routes (or other...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23276v1",
    "title": "CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays",
    "authors": [
      "Hyungyung Lee",
      "Hangyul Yoon",
      "Edward Choi"
    ],
    "abstract": "Chest X-ray plays a central role in thoracic diagnosis, and its interpretation inherently requires multi-step, evidence-grounded reasoning. However, large vision-language models (LVLMs) often generate plausible responses that are not faithfully grounded in diagnostic evidence and provide limited visual evidence for verification, while also requiring costly retraining to support new diagnostic tasks, limiting their reliability and adaptability in clinical settings. To address these limitations, we present CXReasonAgent, a diagnostic agent that integrates a large language model (LLM) with clinically grounded diagnostic tools to perform evidence-grounded diagnostic reasoning using image-derived diagnostic and visual evidence. To evaluate these capabilities, we introduce CXReasonDial, a multi-turn dialogue benchmark with 1,946 dialogues across 12 diagnostic tasks, and show that CXReasonAgent produces faithfully grounded responses, enabling more reliable and verifiable diagnostic reasoning than LVLMs. These findings highlight the importance of integrating clinically grounded diagnostic tools, particularly in safety-critical clinical settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T17:51:21Z",
    "updated": "2026-02-26T17:51:21Z",
    "url": "https://arxiv.org/abs/2602.23276v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23276v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Chest X-ray plays a central role in thoracic diagnosis, and its interpretation inherently requires multi-step, evidence-grounded reasoning.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23266v1",
    "title": "Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems",
    "authors": [
      "Siyuan Liu",
      "Jiahui Xu",
      "Feng Jiang",
      "Kuang Wang",
      "Zefeng Zhao",
      "Chu-Ren Huang",
      "Jinghang Gu",
      "Changqing Yin",
      "Haizhou Li"
    ],
    "abstract": "Achieving human-like responsiveness is a critical yet challenging goal for cascaded spoken dialogue systems. Conventional ASR-LLM-TTS pipelines follow a strictly sequential paradigm, requiring complete transcription and full reasoning before speech synthesis can begin, which results in high response latency. We propose the Discourse-Aware Dual-Track Streaming Response (DDTSR) framework, a low-latency architecture that enables listen-while-thinking and speak-while-thinking. DDTSR is built upon three key mechanisms: (1) connective-guided small-large model synergy, where an auxiliary small model generates minimal-committal discourse connectives while a large model performs knowledge-intensive reasoning in parallel; (2) streaming-based cross-modal collaboration, which dynamically overlaps ASR, LLM inference, and TTS to advance the earliest speakable moment; and (3) curriculum-learning-based discourse continuity enhancement, which maintains coherence and logical consistency between early responses and subsequent reasoning outputs. Experiments on two spoken dialogue benchmarks demonstrate that DDTSR reduces response latency by 19%-51% while preserving discourse quality. Further analysis shows that DDTSR functions as a plug-and-play module compatible with diverse LLM backbones, and remains robust across varying utterance lengths, indicating strong practicality and scalability for real-time spoken interaction.",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "published": "2026-02-26T17:39:56Z",
    "updated": "2026-02-26T17:39:56Z",
    "url": "https://arxiv.org/abs/2602.23266v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23266v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Achieving human-like responsiveness is a critical yet challenging goal for cascaded spoken dialogue systems.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23248v1",
    "title": "Mitigating Legibility Tax with Decoupled Prover-Verifier Games",
    "authors": [
      "Yegon Kim",
      "Juho Lee"
    ],
    "abstract": "As large language models become increasingly capable, it is critical that their outputs can be easily checked by less capable systems. Prover-verifier games can be used to improve checkability of model outputs, but display a degradation in accuracy compared to a baseline trained only to maximize correctness -- a phenonemon named legibility tax. We propose a solution by decoupling the correctness from the checkability condition and instead training a \"translator\" model that turns a fixed solver model's solution into a checkable form. This allows us to first train the solver to maximize correctness, and then train the translator to translate the solver into a checkable form while retaining the solver's answer. To accommodate this new objective of translation, we formulate a decoupled prover-verifier game where the equilibria correspond to faithful and checkable translators.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T17:25:22Z",
    "updated": "2026-02-26T17:25:22Z",
    "url": "https://arxiv.org/abs/2602.23248v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23248v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "As large language models become increasingly capable, it is critical that their outputs can be easily checked by less capable systems.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23242v1",
    "title": "A Model-Free Universal AI",
    "authors": [
      "Yegon Kim",
      "Juho Lee"
    ],
    "abstract": "In general reinforcement learning, all established optimal agents, including AIXI, are model-based, explicitly maintaining and using environment models. This paper introduces Universal AI with Q-Induction (AIQI), the first model-free agent proven to be asymptotically $\\varepsilon$-optimal in general RL. AIQI performs universal induction over distributional action-value functions, instead of policies or environments like previous works. Under a grain of truth condition, we prove that AIQI is strong asymptotically $\\varepsilon$-optimal and asymptotically $\\varepsilon$-Bayes-optimal. Our results significantly expand the diversity of known universal agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T17:21:16Z",
    "updated": "2026-02-26T17:21:16Z",
    "url": "https://arxiv.org/abs/2602.23242v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23242v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "In general reinforcement learning, all established optimal agents, including AIXI, are model-based, explicitly maintaining and using environment models.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23239v1",
    "title": "Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive",
    "authors": [
      "Radha Sarma"
    ],
    "abstract": "AI systems are increasingly deployed in high-stakes contexts -- medical diagnosis, legal research, financial analysis -- under the assumption they can be governed by norms. This paper demonstrates that assumption is formally invalid for optimization-based systems, specifically Large Language Models trained via Reinforcement Learning from Human Feedback (RLHF). We establish that genuine agency requires two necessary and jointly sufficient architectural conditions: the capacity to maintain certain boundaries as non-negotiable constraints rather than tradeable weights (Incommensurability), and a non-inferential mechanism capable of suspending processing when those boundaries are threatened (Apophatic Responsiveness). These conditions apply across all normative domains. RLHF-based systems are constitutively incompatible with both conditions. The operations that make optimization powerful -- unifying all values on a scalar metric and always selecting the highest-scoring output -- are precisely the operations that preclude normative governance. This incompatibility is not a correctable training bug awaiting a technical fix; it is a formal constraint inherent to what optimization is. Consequently, documented failure modes - sycophancy, hallucination, and unfaithful reasoning - are not accidents but structural manifestations. Misaligned deployment triggers a second-order risk we term the Convergence Crisis: when humans are forced to verify AI outputs under metric pressure, they degrade from genuine agents into criteria-checking optimizers, eliminating the only component in the system capable of normative accountability. Beyond the incompatibility proof, the paper's primary positive contribution is a substrate-neutral architectural specification defining what any system -- biological, artificial, or institutional -- must satisfy to qualify as an agent rather than a sophisticated instrument.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T17:16:17Z",
    "updated": "2026-02-26T17:16:17Z",
    "url": "https://arxiv.org/abs/2602.23239v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23239v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "AI systems are increasingly deployed in high-stakes contexts -- medical diagnosis, legal research, financial analysis -- under the assumption they can be governed by norms.",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23235v1",
    "title": "Spatio-Temporal Token Pruning for Efficient High-Resolution GUI Agents",
    "authors": [
      "Zhou Xu",
      "Bowen Zhou",
      "Qi Wang",
      "Shuwen Feng",
      "Jingyu Xiao"
    ],
    "abstract": "Pure-vision GUI agents provide universal interaction capabilities but suffer from severe efficiency bottlenecks due to the massive spatiotemporal redundancy inherent in high-resolution screenshots and historical trajectories. We identify two critical misalignments in existing compression paradigms: the temporal mismatch, where uniform history encoding diverges from the agent's \"fading memory\" attention pattern, and the spatial topology conflict, where unstructured pruning compromises the grid integrity required for precise coordinate grounding, inducing spatial hallucinations. To address these challenges, we introduce GUIPruner, a training-free framework tailored for high-resolution GUI navigation. It synergizes Temporal-Adaptive Resolution (TAR), which eliminates historical redundancy via decay-based resizing, and Stratified Structure-aware Pruning (SSP), which prioritizes interactive foregrounds and semantic anchors while safeguarding global layout. Extensive evaluations across diverse benchmarks demonstrate that GUIPruner consistently achieves state-of-the-art performance, effectively preventing the collapse observed in large-scale models under high compression. Notably, on Qwen2-VL-2B, our method delivers a 3.4x reduction in FLOPs and a 3.3x speedup in vision encoding latency while retaining over 94% of the original performance, enabling real-time, high-precision navigation with minimal resource consumption.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "published": "2026-02-26T17:12:40Z",
    "updated": "2026-02-26T17:12:40Z",
    "url": "https://arxiv.org/abs/2602.23235v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23235v1",
    "relevance_score": 0.0,
    "display_category": "Computer Vision",
    "summary": "Pure-vision GUI agents provide universal interaction capabilities but suffer from severe efficiency bottlenecks due to the massive spatiotemporal redundancy inherent in high-resolution screenshots...",
    "keyword_matches": []
  },
  {
    "arxiv_id": "2602.23232v1",
    "title": "ReCoN-Ipsundrum: An Inspectable Recurrent Persistence Loop Agent with Affect-Coupled Control and Mechanism-Linked Consciousness Indicator Assays",
    "authors": [
      "Aishik Sanyal"
    ],
    "abstract": "Indicator-based approaches to machine consciousness recommend mechanism-linked evidence triangulated across tasks, supported by architectural inspection and causal intervention. Inspired by Humphrey's ipsundrum hypothesis, we implement ReCoN-Ipsundrum, an inspectable agent that extends a ReCoN state machine with a recurrent persistence loop over sensory salience Ns and an optional affect proxy reporting valence/arousal. Across fixed-parameter ablations (ReCoN, Ipsundrum, Ipsundrum+affect), we operationalize Humphrey's qualiaphilia (preference for sensory experience for its own sake) as a familiarity-controlled scenic-over-dull route choice. We find a novelty dissociation: non-affect variants are novelty-sensitive (Delta scenic-entry = 0.07). Affect coupling is stable (Delta scenic-entry = 0.01) even when scenic is less novel (median Delta novelty ~ -0.43). In reward-free exploratory play, the affect variant shows structured local investigation (scan events 31.4 vs. 0.9; cycle score 7.6). In a pain-tail probe, only the affect variant sustains prolonged planned caution (tail duration 90 vs. 5). Lesioning feedback+integration selectively reduces post-stimulus persistence in ipsundrum variants (AUC drop 27.62, 27.9%) while leaving ReCoN unchanged. These dissociations link recurrence -> persistence and affect-coupled control -> preference stability, scanning, and lingering caution, illustrating how indicator-like signatures can be engineered and why mechanistic and causal evidence should accompany behavioral markers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "published": "2026-02-26T17:11:08Z",
    "updated": "2026-02-26T17:11:08Z",
    "url": "https://arxiv.org/abs/2602.23232v1",
    "pdf_url": "https://arxiv.org/pdf/2602.23232v1",
    "relevance_score": 0.0,
    "display_category": "LLMs & Agents",
    "summary": "Indicator-based approaches to machine consciousness recommend mechanism-linked evidence triangulated across tasks, supported by architectural inspection and causal intervention.",
    "keyword_matches": []
  }
]